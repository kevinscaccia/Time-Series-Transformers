{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of train_set : 0.37%\n",
      "Proportion of valid_set : 0.13%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc8cdc3eb60>]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from experiment import Experiment\n",
    "from utils.plot import plot_predictions\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "solar_power = pd.read_csv('./data/solarpanelspower/PV_Elec_Gas2.csv').rename(columns={'Unnamed: 0':'date'}).set_index('date')\n",
    "def generate_data(num_steps: int, interval: float = 0.1) -> None:\n",
    "    x = np.linspace(0, num_steps * interval, num_steps)\n",
    "    y = np.sin(x) + np.random.normal(0, 0.1, x.shape)\n",
    "    return y\n",
    "\n",
    "\n",
    "solar_power['Elec_kW'] =generate_data(len(solar_power))\n",
    "\n",
    "\n",
    "train_set = solar_power[:'2014-10-31']\n",
    "valid_set = solar_power['2014-11-01':'2015-11-18']\n",
    "# test_set = solar_power['2019-11-18':]\n",
    "print('Proportion of train_set : {:.2f}%'.format(len(train_set)/len(solar_power)))\n",
    "print('Proportion of valid_set : {:.2f}%'.format(len(valid_set)/len(solar_power)))\n",
    "# print('Proportion of test_set : {:.2f}%'.format(len(test_set)/len(solar_power)))\n",
    "plt.plot(train_set.Elec_kW.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### SimpleTransformer (Medium Article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of weights: 532097\n",
      "TransformerWithPE(\n",
      "  (positional_encoding): PositionalEncoding(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder_embedding): Linear(in_features=1, out_features=128, bias=True)\n",
      "  (decoder_embedding): Linear(in_features=1, out_features=128, bias=True)\n",
      "  (output_layer): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (transformer): Transformer(\n",
      "    (encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0-1): 2 x TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (decoder): TransformerDecoder(\n",
      "      (layers): ModuleList(\n",
      "        (0-1): 2 x TransformerDecoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (multihead_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (dropout3): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import time\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "\n",
    "# Taken from https://pytorch.org/tutorials/beginner/transformer_tutorial.html,\n",
    "# only modified to account for \"batch first\".\n",
    "class PositionalEncoding(torch.nn.Module):\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000) -> None:\n",
    "        super().__init__()\n",
    "        self.dropout = torch.nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model)\n",
    "        )\n",
    "        pe = torch.zeros(1, max_len, d_model)\n",
    "        pe[0, :, 0::2] = torch.sin(position * div_term)\n",
    "        pe[0, :, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Adds positional encoding to the given tensor.\n",
    "\n",
    "        Args:\n",
    "            x: tensor to add PE to [bs, seq_len, embed_dim]\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: tensor with PE [bs, seq_len, embed_dim]\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:, : x.size(1)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class TransformerWithPE(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self, in_dim: int, out_dim: int, embed_dim: int, num_heads: int, \n",
    "        num_layers, dim_feedforward\n",
    "    ) -> None:\n",
    "        \"\"\"Initializes a transformer model with positional encoding.\n",
    "\n",
    "        Args:\n",
    "            in_dim: number of input features\n",
    "            out_dim: number of features to predict\n",
    "            embed_dim: embed features to this dimension\n",
    "            num_heads: number of transformer heads\n",
    "            num_layers: number of encoder and decoder layers\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.train_loss_history = []\n",
    "        self.validation_loss_history = []\n",
    "        #\n",
    "        self.positional_encoding = PositionalEncoding(embed_dim)\n",
    "        self.encoder_embedding = torch.nn.Linear(in_features=in_dim, out_features=embed_dim)\n",
    "        self.decoder_embedding = torch.nn.Linear(in_features=out_dim, out_features=embed_dim)\n",
    "        self.output_layer = torch.nn.Linear(in_features=embed_dim, out_features=out_dim)\n",
    "        self.transformer = torch.nn.Transformer(\n",
    "            nhead=num_heads,\n",
    "            num_encoder_layers=num_layers,\n",
    "            num_decoder_layers=num_layers,\n",
    "            d_model=embed_dim,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            batch_first=True,\n",
    "        )\n",
    "    def is_transformer(self, ): return True\n",
    "\n",
    "    def forward(self, src: torch.Tensor, tgt: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward function of the model.\n",
    "\n",
    "        Args:\n",
    "            src: input sequence to the encoder [bs, src_seq_len, num_features]\n",
    "            tgt: input sequence to the decoder [bs, tgt_seq_len, num_features]\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: predicted sequence [bs, tgt_seq_len, feat_dim]\n",
    "        \"\"\"\n",
    "        # if self.train:\n",
    "        # Add noise to decoder inputs during training\n",
    "        # tgt = tgt + torch.normal(0, 0.1, size=tgt.shape).to(tgt.device)\n",
    "        # Embed encoder input and add positional encoding [bs, src_seq_len, embed_dim]\n",
    "        src = self.encoder_embedding(src)\n",
    "        src = self.positional_encoding(src)\n",
    "        # Generate mask to avoid attention to future outputs.[tgt_seq_len, tgt_seq_len]\n",
    "        tgt_mask = torch.nn.Transformer.generate_square_subsequent_mask(tgt.shape[1])\n",
    "        # Embed decoder input and add positional encoding. [bs, tgt_seq_len, embed_dim]\n",
    "        tgt = self.decoder_embedding(tgt)\n",
    "        tgt = self.positional_encoding(tgt)\n",
    "        # Get prediction from transformer and map to output dimension.[bs, tgt_seq_len, embed_dim]\n",
    "        pred = self.transformer(src, tgt, tgt_mask=tgt_mask)\n",
    "        pred = self.output_layer(pred)\n",
    "\n",
    "        return pred\n",
    "\n",
    "    def validate(self, data):\n",
    "        val_loader = DataLoader(data, batch_size=1024, shuffle=False)\n",
    "        loss_fn = nn.MSELoss()\n",
    "        val_loss = 0.0\n",
    "        #\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            for enc_x, dec_x, tgt_y in val_loader:\n",
    "                pred_y = self(enc_x, dec_x)\n",
    "                val_loss += loss_fn(pred_y, tgt_y)\n",
    "        val_loss = val_loss/len(val_loader)\n",
    "        return val_loss\n",
    "    \n",
    "    def predict(self, src, forecast_horizon):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            output = torch.zeros(1, forecast_horizon + 1, 1).to('cuda')\n",
    "            output[0, 0, 0] = src[0, -1] # first value\n",
    "            for i in range(forecast_horizon):\n",
    "                y = self(src, output)[0,i,0]\n",
    "                output[0,i+1,0] = y\n",
    "        return output[:,1:,:] # remove first value (copy from last history step)\n",
    "\n",
    "\n",
    "    def fit(self, conf):\n",
    "        expected_vars = ['epochs','lr','batch_size','train_dataset']\n",
    "        for v in expected_vars:\n",
    "            assert v in conf.keys(), f'Key \"{v}\" is missing on params dict'\n",
    "        #\n",
    "        epochs = conf['epochs']\n",
    "        verbose = conf['verbose']\n",
    "        train_dataset = conf['train_dataset']\n",
    "        val_dataset = conf.get('train_dataset',None)\n",
    "        #\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=conf['lr'])\n",
    "        loss_fn = nn.MSELoss()\n",
    "        train_loader = DataLoader(train_dataset, batch_size=conf['batch_size'], shuffle=True)\n",
    "        for epoch_i in range(epochs):\n",
    "            timr = time.time()\n",
    "            epoch_loss = .0\n",
    "            val_loss = -1\n",
    "            for enc_x, dec_x, tgt_y in train_loader:\n",
    "                optimizer.zero_grad() # current batch zero-out the loss\n",
    "                pred_y = self(enc_x, dec_x)\n",
    "                loss = loss_fn(pred_y, tgt_y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                epoch_loss += loss        \n",
    "            # end epoch\n",
    "            epoch_loss = epoch_loss/len(train_loader)\n",
    "            # if there are a validation set\n",
    "            if val_dataset is not None:\n",
    "                val_loss = self.validate(val_dataset)\n",
    "                self.validation_loss_history.append(val_loss.to('cpu').detach().numpy())\n",
    "            self.train_loss_history.append(epoch_loss.to('cpu').detach().numpy())\n",
    "            #     \n",
    "            timr = time.time() - timr\n",
    "            if verbose: \n",
    "                print(f'Epoch {epoch_i+1}/{epochs} [{timr:.3f}secs] -> Train loss: {epoch_loss:.5f} | Validation loss: {val_loss:.5f}')\n",
    "\n",
    "\n",
    "input_len = 100\n",
    "fh = 128\n",
    "d_model = 128\n",
    "model_params={\n",
    "    'in_dim': 1, \n",
    "    'out_dim':1, \n",
    "    'embed_dim': d_model, \n",
    "    'num_heads': 8, \n",
    "    'num_layers': 2,\n",
    "    'dim_feedforward':128\n",
    "}\n",
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "gc.collect()\n",
    "model = TransformerWithPE(**model_params)\n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print('Num of weights:',pytorch_total_params)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/512 [0.893secs] -> Train loss: 0.91340 | Validation loss: 8.46183\n",
      "Epoch 2/512 [0.744secs] -> Train loss: 8.46183 | Validation loss: 1.30099\n",
      "Epoch 3/512 [0.732secs] -> Train loss: 1.30099 | Validation loss: 0.58352\n",
      "Epoch 4/512 [0.728secs] -> Train loss: 0.58352 | Validation loss: 1.22121\n",
      "Epoch 5/512 [0.789secs] -> Train loss: 1.22121 | Validation loss: 1.05001\n",
      "Epoch 6/512 [0.724secs] -> Train loss: 1.05001 | Validation loss: 0.64852\n",
      "Epoch 7/512 [0.721secs] -> Train loss: 0.64852 | Validation loss: 0.44185\n",
      "Epoch 8/512 [0.722secs] -> Train loss: 0.44185 | Validation loss: 0.46174\n",
      "Epoch 9/512 [0.723secs] -> Train loss: 0.46174 | Validation loss: 0.56264\n",
      "Epoch 10/512 [0.739secs] -> Train loss: 0.56264 | Validation loss: 0.59458\n",
      "Epoch 11/512 [0.733secs] -> Train loss: 0.59458 | Validation loss: 0.53867\n",
      "Epoch 12/512 [0.734secs] -> Train loss: 0.53867 | Validation loss: 0.45506\n",
      "Epoch 13/512 [0.737secs] -> Train loss: 0.45506 | Validation loss: 0.40236\n",
      "Epoch 14/512 [0.735secs] -> Train loss: 0.40236 | Validation loss: 0.40737\n",
      "Epoch 15/512 [0.728secs] -> Train loss: 0.40737 | Validation loss: 0.44689\n",
      "Epoch 16/512 [0.737secs] -> Train loss: 0.44689 | Validation loss: 0.47072\n",
      "Epoch 17/512 [0.738secs] -> Train loss: 0.47072 | Validation loss: 0.45502\n",
      "Epoch 18/512 [0.735secs] -> Train loss: 0.45502 | Validation loss: 0.41198\n",
      "Epoch 19/512 [0.736secs] -> Train loss: 0.41198 | Validation loss: 0.36801\n",
      "Epoch 20/512 [0.735secs] -> Train loss: 0.36801 | Validation loss: 0.34361\n",
      "Epoch 21/512 [0.735secs] -> Train loss: 0.34361 | Validation loss: 0.34058\n",
      "Epoch 22/512 [0.736secs] -> Train loss: 0.34058 | Validation loss: 0.34210\n",
      "Epoch 23/512 [0.738secs] -> Train loss: 0.34210 | Validation loss: 0.32756\n",
      "Epoch 24/512 [0.736secs] -> Train loss: 0.32756 | Validation loss: 0.28915\n",
      "Epoch 25/512 [0.740secs] -> Train loss: 0.28915 | Validation loss: 0.23684\n",
      "Epoch 26/512 [0.737secs] -> Train loss: 0.23684 | Validation loss: 0.19007\n",
      "Epoch 27/512 [0.739secs] -> Train loss: 0.19007 | Validation loss: 0.15849\n",
      "Epoch 28/512 [0.744secs] -> Train loss: 0.15849 | Validation loss: 0.13053\n",
      "Epoch 29/512 [0.750secs] -> Train loss: 0.13053 | Validation loss: 0.08896\n",
      "Epoch 30/512 [0.752secs] -> Train loss: 0.08896 | Validation loss: 0.04953\n",
      "Epoch 31/512 [0.752secs] -> Train loss: 0.04953 | Validation loss: 0.05610\n",
      "Epoch 32/512 [0.753secs] -> Train loss: 0.05610 | Validation loss: 0.09900\n",
      "Epoch 33/512 [0.754secs] -> Train loss: 0.09900 | Validation loss: 0.11325\n",
      "Epoch 34/512 [0.758secs] -> Train loss: 0.11325 | Validation loss: 0.09614\n",
      "Epoch 35/512 [0.751secs] -> Train loss: 0.09614 | Validation loss: 0.07656\n",
      "Epoch 36/512 [0.758secs] -> Train loss: 0.07656 | Validation loss: 0.05819\n",
      "Epoch 37/512 [0.781secs] -> Train loss: 0.05819 | Validation loss: 0.04253\n",
      "Epoch 38/512 [0.772secs] -> Train loss: 0.04253 | Validation loss: 0.03943\n",
      "Epoch 39/512 [0.776secs] -> Train loss: 0.03943 | Validation loss: 0.04945\n",
      "Epoch 40/512 [0.766secs] -> Train loss: 0.04945 | Validation loss: 0.05964\n",
      "Epoch 41/512 [0.771secs] -> Train loss: 0.05964 | Validation loss: 0.06196\n",
      "Epoch 42/512 [0.757secs] -> Train loss: 0.06196 | Validation loss: 0.06014\n",
      "Epoch 43/512 [0.758secs] -> Train loss: 0.06014 | Validation loss: 0.05843\n",
      "Epoch 44/512 [0.747secs] -> Train loss: 0.05843 | Validation loss: 0.05478\n",
      "Epoch 45/512 [0.744secs] -> Train loss: 0.05478 | Validation loss: 0.04684\n",
      "Epoch 46/512 [0.752secs] -> Train loss: 0.04684 | Validation loss: 0.03838\n",
      "Epoch 47/512 [0.763secs] -> Train loss: 0.03838 | Validation loss: 0.03471\n",
      "Epoch 48/512 [0.752secs] -> Train loss: 0.03471 | Validation loss: 0.03531\n",
      "Epoch 49/512 [0.756secs] -> Train loss: 0.03531 | Validation loss: 0.03647\n",
      "Epoch 50/512 [0.740secs] -> Train loss: 0.03647 | Validation loss: 0.03804\n",
      "Epoch 51/512 [0.750secs] -> Train loss: 0.03804 | Validation loss: 0.04065\n",
      "Epoch 52/512 [0.752secs] -> Train loss: 0.04065 | Validation loss: 0.04114\n",
      "Epoch 53/512 [0.749secs] -> Train loss: 0.04114 | Validation loss: 0.03767\n",
      "Epoch 54/512 [0.742secs] -> Train loss: 0.03767 | Validation loss: 0.03347\n",
      "Epoch 55/512 [0.742secs] -> Train loss: 0.03347 | Validation loss: 0.03124\n",
      "Epoch 56/512 [0.743secs] -> Train loss: 0.03124 | Validation loss: 0.03007\n",
      "Epoch 57/512 [0.740secs] -> Train loss: 0.03007 | Validation loss: 0.02938\n",
      "Epoch 58/512 [0.741secs] -> Train loss: 0.02938 | Validation loss: 0.03015\n",
      "Epoch 59/512 [0.740secs] -> Train loss: 0.03015 | Validation loss: 0.03159\n",
      "Epoch 60/512 [0.740secs] -> Train loss: 0.03159 | Validation loss: 0.03172\n",
      "Epoch 61/512 [0.741secs] -> Train loss: 0.03172 | Validation loss: 0.03066\n",
      "Epoch 62/512 [0.739secs] -> Train loss: 0.03066 | Validation loss: 0.02962\n",
      "Epoch 63/512 [0.741secs] -> Train loss: 0.02962 | Validation loss: 0.02844\n",
      "Epoch 64/512 [0.740secs] -> Train loss: 0.02844 | Validation loss: 0.02684\n",
      "Epoch 65/512 [0.743secs] -> Train loss: 0.02684 | Validation loss: 0.02597\n",
      "Epoch 66/512 [0.744secs] -> Train loss: 0.02597 | Validation loss: 0.02625\n",
      "Epoch 67/512 [0.743secs] -> Train loss: 0.02625 | Validation loss: 0.02658\n",
      "Epoch 68/512 [0.744secs] -> Train loss: 0.02658 | Validation loss: 0.02659\n",
      "Epoch 69/512 [0.742secs] -> Train loss: 0.02659 | Validation loss: 0.02659\n",
      "Epoch 70/512 [0.741secs] -> Train loss: 0.02659 | Validation loss: 0.02609\n",
      "Epoch 71/512 [0.741secs] -> Train loss: 0.02609 | Validation loss: 0.02507\n",
      "Epoch 72/512 [0.739secs] -> Train loss: 0.02507 | Validation loss: 0.02444\n",
      "Epoch 73/512 [0.743secs] -> Train loss: 0.02444 | Validation loss: 0.02424\n",
      "Epoch 74/512 [0.743secs] -> Train loss: 0.02424 | Validation loss: 0.02410\n",
      "Epoch 75/512 [0.740secs] -> Train loss: 0.02410 | Validation loss: 0.02420\n",
      "Epoch 76/512 [0.745secs] -> Train loss: 0.02420 | Validation loss: 0.02438\n",
      "Epoch 77/512 [0.741secs] -> Train loss: 0.02438 | Validation loss: 0.02415\n",
      "Epoch 78/512 [0.741secs] -> Train loss: 0.02415 | Validation loss: 0.02375\n",
      "Epoch 79/512 [0.742secs] -> Train loss: 0.02375 | Validation loss: 0.02343\n",
      "Epoch 80/512 [0.741secs] -> Train loss: 0.02343 | Validation loss: 0.02305\n",
      "Epoch 81/512 [0.741secs] -> Train loss: 0.02305 | Validation loss: 0.02284\n",
      "Epoch 82/512 [0.804secs] -> Train loss: 0.02284 | Validation loss: 0.02290\n",
      "Epoch 83/512 [0.744secs] -> Train loss: 0.02290 | Validation loss: 0.02290\n",
      "Epoch 84/512 [0.742secs] -> Train loss: 0.02290 | Validation loss: 0.02281\n",
      "Epoch 85/512 [0.742secs] -> Train loss: 0.02281 | Validation loss: 0.02269\n",
      "Epoch 86/512 [0.743secs] -> Train loss: 0.02269 | Validation loss: 0.02241\n",
      "Epoch 87/512 [0.740secs] -> Train loss: 0.02241 | Validation loss: 0.02216\n",
      "Epoch 88/512 [0.741secs] -> Train loss: 0.02216 | Validation loss: 0.02205\n",
      "Epoch 89/512 [0.739secs] -> Train loss: 0.02205 | Validation loss: 0.02197\n",
      "Epoch 90/512 [0.738secs] -> Train loss: 0.02197 | Validation loss: 0.02194\n",
      "Epoch 91/512 [0.740secs] -> Train loss: 0.02194 | Validation loss: 0.02190\n",
      "Epoch 92/512 [0.740secs] -> Train loss: 0.02190 | Validation loss: 0.02175\n",
      "Epoch 93/512 [0.742secs] -> Train loss: 0.02175 | Validation loss: 0.02159\n",
      "Epoch 94/512 [0.740secs] -> Train loss: 0.02159 | Validation loss: 0.02144\n",
      "Epoch 95/512 [0.739secs] -> Train loss: 0.02144 | Validation loss: 0.02130\n",
      "Epoch 96/512 [0.742secs] -> Train loss: 0.02130 | Validation loss: 0.02126\n",
      "Epoch 97/512 [0.736secs] -> Train loss: 0.02126 | Validation loss: 0.02120\n",
      "Epoch 98/512 [0.742secs] -> Train loss: 0.02120 | Validation loss: 0.02111\n",
      "Epoch 99/512 [0.740secs] -> Train loss: 0.02111 | Validation loss: 0.02101\n",
      "Epoch 100/512 [0.738secs] -> Train loss: 0.02101 | Validation loss: 0.02087\n",
      "Epoch 101/512 [0.740secs] -> Train loss: 0.02087 | Validation loss: 0.02077\n",
      "Epoch 102/512 [0.740secs] -> Train loss: 0.02077 | Validation loss: 0.02069\n",
      "Epoch 103/512 [0.741secs] -> Train loss: 0.02069 | Validation loss: 0.02063\n",
      "Epoch 104/512 [0.742secs] -> Train loss: 0.02063 | Validation loss: 0.02056\n",
      "Epoch 105/512 [0.740secs] -> Train loss: 0.02056 | Validation loss: 0.02045\n",
      "Epoch 106/512 [0.745secs] -> Train loss: 0.02045 | Validation loss: 0.02035\n",
      "Epoch 107/512 [0.743secs] -> Train loss: 0.02035 | Validation loss: 0.02026\n",
      "Epoch 108/512 [0.744secs] -> Train loss: 0.02026 | Validation loss: 0.02020\n",
      "Epoch 109/512 [0.757secs] -> Train loss: 0.02020 | Validation loss: 0.02013\n",
      "Epoch 110/512 [0.743secs] -> Train loss: 0.02013 | Validation loss: 0.02005\n",
      "Epoch 111/512 [0.744secs] -> Train loss: 0.02005 | Validation loss: 0.01997\n",
      "Epoch 112/512 [0.738secs] -> Train loss: 0.01997 | Validation loss: 0.01989\n",
      "Epoch 113/512 [0.726secs] -> Train loss: 0.01989 | Validation loss: 0.01982\n",
      "Epoch 114/512 [0.724secs] -> Train loss: 0.01982 | Validation loss: 0.01976\n",
      "Epoch 115/512 [0.726secs] -> Train loss: 0.01976 | Validation loss: 0.01970\n",
      "Epoch 116/512 [0.727secs] -> Train loss: 0.01970 | Validation loss: 0.01963\n",
      "Epoch 117/512 [0.727secs] -> Train loss: 0.01963 | Validation loss: 0.01956\n",
      "Epoch 118/512 [0.726secs] -> Train loss: 0.01956 | Validation loss: 0.01950\n",
      "Epoch 119/512 [0.725secs] -> Train loss: 0.01950 | Validation loss: 0.01946\n",
      "Epoch 120/512 [0.723secs] -> Train loss: 0.01946 | Validation loss: 0.01940\n",
      "Epoch 121/512 [0.724secs] -> Train loss: 0.01940 | Validation loss: 0.01935\n",
      "Epoch 122/512 [0.725secs] -> Train loss: 0.01935 | Validation loss: 0.01930\n",
      "Epoch 123/512 [0.726secs] -> Train loss: 0.01930 | Validation loss: 0.01925\n",
      "Epoch 124/512 [0.727secs] -> Train loss: 0.01925 | Validation loss: 0.01921\n",
      "Epoch 125/512 [0.730secs] -> Train loss: 0.01921 | Validation loss: 0.01917\n",
      "Epoch 126/512 [0.728secs] -> Train loss: 0.01917 | Validation loss: 0.01913\n",
      "Epoch 127/512 [0.726secs] -> Train loss: 0.01913 | Validation loss: 0.01909\n",
      "Epoch 128/512 [0.730secs] -> Train loss: 0.01909 | Validation loss: 0.01906\n",
      "Epoch 129/512 [0.736secs] -> Train loss: 0.01906 | Validation loss: 0.01903\n",
      "Epoch 130/512 [0.742secs] -> Train loss: 0.01903 | Validation loss: 0.01900\n",
      "Epoch 131/512 [0.749secs] -> Train loss: 0.01900 | Validation loss: 0.01896\n",
      "Epoch 132/512 [0.746secs] -> Train loss: 0.01896 | Validation loss: 0.01894\n",
      "Epoch 133/512 [0.746secs] -> Train loss: 0.01894 | Validation loss: 0.01891\n",
      "Epoch 134/512 [0.748secs] -> Train loss: 0.01891 | Validation loss: 0.01889\n",
      "Epoch 135/512 [0.746secs] -> Train loss: 0.01889 | Validation loss: 0.01886\n",
      "Epoch 136/512 [0.745secs] -> Train loss: 0.01886 | Validation loss: 0.01884\n",
      "Epoch 137/512 [0.744secs] -> Train loss: 0.01884 | Validation loss: 0.01882\n",
      "Epoch 138/512 [0.743secs] -> Train loss: 0.01882 | Validation loss: 0.01880\n",
      "Epoch 139/512 [0.737secs] -> Train loss: 0.01880 | Validation loss: 0.01878\n",
      "Epoch 140/512 [0.736secs] -> Train loss: 0.01878 | Validation loss: 0.01876\n",
      "Epoch 141/512 [0.727secs] -> Train loss: 0.01876 | Validation loss: 0.01874\n",
      "Epoch 142/512 [0.729secs] -> Train loss: 0.01874 | Validation loss: 0.01872\n",
      "Epoch 143/512 [0.732secs] -> Train loss: 0.01872 | Validation loss: 0.01871\n",
      "Epoch 144/512 [0.731secs] -> Train loss: 0.01871 | Validation loss: 0.01869\n",
      "Epoch 145/512 [0.734secs] -> Train loss: 0.01869 | Validation loss: 0.01867\n",
      "Epoch 146/512 [0.729secs] -> Train loss: 0.01867 | Validation loss: 0.01866\n",
      "Epoch 147/512 [0.723secs] -> Train loss: 0.01866 | Validation loss: 0.01864\n",
      "Epoch 148/512 [0.718secs] -> Train loss: 0.01864 | Validation loss: 0.01863\n",
      "Epoch 149/512 [0.716secs] -> Train loss: 0.01863 | Validation loss: 0.01862\n",
      "Epoch 150/512 [0.715secs] -> Train loss: 0.01862 | Validation loss: 0.01860\n",
      "Epoch 151/512 [0.720secs] -> Train loss: 0.01860 | Validation loss: 0.01859\n",
      "Epoch 152/512 [0.725secs] -> Train loss: 0.01859 | Validation loss: 0.01857\n",
      "Epoch 153/512 [0.727secs] -> Train loss: 0.01857 | Validation loss: 0.01856\n",
      "Epoch 154/512 [0.727secs] -> Train loss: 0.01856 | Validation loss: 0.01855\n",
      "Epoch 155/512 [0.727secs] -> Train loss: 0.01855 | Validation loss: 0.01853\n",
      "Epoch 156/512 [0.726secs] -> Train loss: 0.01853 | Validation loss: 0.01852\n",
      "Epoch 157/512 [0.725secs] -> Train loss: 0.01852 | Validation loss: 0.01851\n",
      "Epoch 158/512 [0.726secs] -> Train loss: 0.01851 | Validation loss: 0.01850\n",
      "Epoch 159/512 [0.786secs] -> Train loss: 0.01850 | Validation loss: 0.01848\n",
      "Epoch 160/512 [0.726secs] -> Train loss: 0.01848 | Validation loss: 0.01847\n",
      "Epoch 161/512 [0.728secs] -> Train loss: 0.01847 | Validation loss: 0.01846\n",
      "Epoch 162/512 [0.726secs] -> Train loss: 0.01846 | Validation loss: 0.01845\n",
      "Epoch 163/512 [0.729secs] -> Train loss: 0.01845 | Validation loss: 0.01844\n",
      "Epoch 164/512 [0.727secs] -> Train loss: 0.01844 | Validation loss: 0.01843\n",
      "Epoch 165/512 [0.727secs] -> Train loss: 0.01843 | Validation loss: 0.01841\n",
      "Epoch 166/512 [0.726secs] -> Train loss: 0.01841 | Validation loss: 0.01840\n",
      "Epoch 167/512 [0.726secs] -> Train loss: 0.01840 | Validation loss: 0.01839\n",
      "Epoch 168/512 [0.728secs] -> Train loss: 0.01839 | Validation loss: 0.01838\n",
      "Epoch 169/512 [0.725secs] -> Train loss: 0.01838 | Validation loss: 0.01837\n",
      "Epoch 170/512 [0.723secs] -> Train loss: 0.01837 | Validation loss: 0.01836\n",
      "Epoch 171/512 [0.727secs] -> Train loss: 0.01836 | Validation loss: 0.01835\n",
      "Epoch 172/512 [0.729secs] -> Train loss: 0.01835 | Validation loss: 0.01834\n",
      "Epoch 173/512 [0.727secs] -> Train loss: 0.01834 | Validation loss: 0.01833\n",
      "Epoch 174/512 [0.726secs] -> Train loss: 0.01833 | Validation loss: 0.01832\n",
      "Epoch 175/512 [0.727secs] -> Train loss: 0.01832 | Validation loss: 0.01830\n",
      "Epoch 176/512 [0.723secs] -> Train loss: 0.01830 | Validation loss: 0.01829\n",
      "Epoch 177/512 [0.723secs] -> Train loss: 0.01829 | Validation loss: 0.01828\n",
      "Epoch 178/512 [0.746secs] -> Train loss: 0.01828 | Validation loss: 0.01827\n",
      "Epoch 179/512 [0.726secs] -> Train loss: 0.01827 | Validation loss: 0.01826\n",
      "Epoch 180/512 [0.735secs] -> Train loss: 0.01826 | Validation loss: 0.01825\n",
      "Epoch 181/512 [0.736secs] -> Train loss: 0.01825 | Validation loss: 0.01824\n",
      "Epoch 182/512 [0.746secs] -> Train loss: 0.01824 | Validation loss: 0.01823\n",
      "Epoch 183/512 [0.730secs] -> Train loss: 0.01823 | Validation loss: 0.01822\n",
      "Epoch 184/512 [0.729secs] -> Train loss: 0.01822 | Validation loss: 0.01821\n",
      "Epoch 185/512 [0.728secs] -> Train loss: 0.01821 | Validation loss: 0.01820\n",
      "Epoch 186/512 [0.721secs] -> Train loss: 0.01820 | Validation loss: 0.01819\n",
      "Epoch 187/512 [0.720secs] -> Train loss: 0.01819 | Validation loss: 0.01818\n",
      "Epoch 188/512 [0.721secs] -> Train loss: 0.01818 | Validation loss: 0.01817\n",
      "Epoch 189/512 [0.715secs] -> Train loss: 0.01817 | Validation loss: 0.01816\n",
      "Epoch 190/512 [0.716secs] -> Train loss: 0.01816 | Validation loss: 0.01815\n",
      "Epoch 191/512 [0.732secs] -> Train loss: 0.01815 | Validation loss: 0.01814\n",
      "Epoch 192/512 [0.738secs] -> Train loss: 0.01814 | Validation loss: 0.01813\n",
      "Epoch 193/512 [0.727secs] -> Train loss: 0.01813 | Validation loss: 0.01812\n",
      "Epoch 194/512 [0.730secs] -> Train loss: 0.01812 | Validation loss: 0.01811\n",
      "Epoch 195/512 [0.740secs] -> Train loss: 0.01811 | Validation loss: 0.01810\n",
      "Epoch 196/512 [0.740secs] -> Train loss: 0.01810 | Validation loss: 0.01809\n",
      "Epoch 197/512 [0.751secs] -> Train loss: 0.01809 | Validation loss: 0.01808\n",
      "Epoch 198/512 [0.754secs] -> Train loss: 0.01808 | Validation loss: 0.01807\n",
      "Epoch 199/512 [0.755secs] -> Train loss: 0.01807 | Validation loss: 0.01806\n",
      "Epoch 200/512 [0.758secs] -> Train loss: 0.01806 | Validation loss: 0.01805\n",
      "Epoch 201/512 [0.755secs] -> Train loss: 0.01805 | Validation loss: 0.01804\n",
      "Epoch 202/512 [0.740secs] -> Train loss: 0.01804 | Validation loss: 0.01803\n",
      "Epoch 203/512 [0.737secs] -> Train loss: 0.01803 | Validation loss: 0.01802\n",
      "Epoch 204/512 [0.739secs] -> Train loss: 0.01802 | Validation loss: 0.01801\n",
      "Epoch 205/512 [0.736secs] -> Train loss: 0.01801 | Validation loss: 0.01800\n",
      "Epoch 206/512 [0.741secs] -> Train loss: 0.01800 | Validation loss: 0.01799\n",
      "Epoch 207/512 [0.740secs] -> Train loss: 0.01799 | Validation loss: 0.01798\n",
      "Epoch 208/512 [0.739secs] -> Train loss: 0.01798 | Validation loss: 0.01798\n",
      "Epoch 209/512 [0.738secs] -> Train loss: 0.01798 | Validation loss: 0.01797\n",
      "Epoch 210/512 [0.741secs] -> Train loss: 0.01797 | Validation loss: 0.01795\n",
      "Epoch 211/512 [0.749secs] -> Train loss: 0.01795 | Validation loss: 0.01794\n",
      "Epoch 212/512 [0.742secs] -> Train loss: 0.01794 | Validation loss: 0.01792\n",
      "Epoch 213/512 [0.737secs] -> Train loss: 0.01792 | Validation loss: 0.01792\n",
      "Epoch 214/512 [0.737secs] -> Train loss: 0.01792 | Validation loss: 0.01791\n",
      "Epoch 215/512 [0.739secs] -> Train loss: 0.01791 | Validation loss: 0.01790\n",
      "Epoch 216/512 [0.739secs] -> Train loss: 0.01790 | Validation loss: 0.01789\n",
      "Epoch 217/512 [0.737secs] -> Train loss: 0.01789 | Validation loss: 0.01787\n",
      "Epoch 218/512 [0.739secs] -> Train loss: 0.01787 | Validation loss: 0.01786\n",
      "Epoch 219/512 [0.736secs] -> Train loss: 0.01786 | Validation loss: 0.01786\n",
      "Epoch 220/512 [0.725secs] -> Train loss: 0.01786 | Validation loss: 0.01785\n",
      "Epoch 221/512 [0.738secs] -> Train loss: 0.01785 | Validation loss: 0.01783\n",
      "Epoch 222/512 [0.739secs] -> Train loss: 0.01783 | Validation loss: 0.01782\n",
      "Epoch 223/512 [0.737secs] -> Train loss: 0.01782 | Validation loss: 0.01781\n",
      "Epoch 224/512 [0.741secs] -> Train loss: 0.01781 | Validation loss: 0.01780\n",
      "Epoch 225/512 [0.740secs] -> Train loss: 0.01780 | Validation loss: 0.01779\n",
      "Epoch 226/512 [0.739secs] -> Train loss: 0.01779 | Validation loss: 0.01778\n",
      "Epoch 227/512 [0.739secs] -> Train loss: 0.01778 | Validation loss: 0.01777\n",
      "Epoch 228/512 [0.737secs] -> Train loss: 0.01777 | Validation loss: 0.01776\n",
      "Epoch 229/512 [0.744secs] -> Train loss: 0.01776 | Validation loss: 0.01775\n",
      "Epoch 230/512 [0.740secs] -> Train loss: 0.01775 | Validation loss: 0.01774\n",
      "Epoch 231/512 [0.745secs] -> Train loss: 0.01774 | Validation loss: 0.01773\n",
      "Epoch 232/512 [0.738secs] -> Train loss: 0.01773 | Validation loss: 0.01772\n",
      "Epoch 233/512 [0.735secs] -> Train loss: 0.01772 | Validation loss: 0.01771\n",
      "Epoch 234/512 [0.750secs] -> Train loss: 0.01771 | Validation loss: 0.01769\n",
      "Epoch 235/512 [0.758secs] -> Train loss: 0.01769 | Validation loss: 0.01768\n",
      "Epoch 236/512 [0.822secs] -> Train loss: 0.01768 | Validation loss: 0.01767\n",
      "Epoch 237/512 [0.759secs] -> Train loss: 0.01767 | Validation loss: 0.01766\n",
      "Epoch 238/512 [0.763secs] -> Train loss: 0.01766 | Validation loss: 0.01765\n",
      "Epoch 239/512 [0.757secs] -> Train loss: 0.01765 | Validation loss: 0.01763\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "exp = Experiment(\n",
    "    {\n",
    "        # Model\n",
    "        'model': model,\n",
    "        'input_len':input_len,\n",
    "        'feature_dim':1,\n",
    "        'forecast_horizon':fh,\n",
    "        # Data\n",
    "        'frequency':'daily',\n",
    "        'scaler':None,#MinMaxScaler((-1,1)),\n",
    "        'decompose': False, #detrend and de-sazonalize\n",
    "        'freq':1,\n",
    "        # Others\n",
    "        'device':'cuda',\n",
    "        'verbose':True,\n",
    "    })\n",
    "#\n",
    "\n",
    "exp.set_dataset(linear_serie=train_set.Elec_kW.values, train=True)\n",
    "exp.set_dataset(linear_serie=valid_set.Elec_kW.values, validation=True)\n",
    "\n",
    "#\n",
    "exp.train({\n",
    "    'epochs':512,\n",
    "    'lr':0.001,\n",
    "    'batch_size':1024,\n",
    "    'verbose':True,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.7939 | MAPE: 1.9633 | sMAPE: 1.3922\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "$%{y:.2f}",
         "line": {
          "color": "#0099ff"
         },
         "mode": "lines",
         "name": "History",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499,
          500,
          501,
          502,
          503,
          504,
          505,
          506,
          507,
          508,
          509,
          510,
          511,
          512,
          513,
          514,
          515,
          516,
          517,
          518,
          519,
          520,
          521,
          522,
          523,
          524,
          525,
          526,
          527,
          528,
          529,
          530,
          531,
          532,
          533,
          534,
          535,
          536,
          537,
          538,
          539,
          540,
          541,
          542,
          543,
          544,
          545,
          546,
          547,
          548,
          549,
          550,
          551,
          552,
          553,
          554,
          555,
          556,
          557,
          558,
          559,
          560,
          561,
          562,
          563,
          564,
          565,
          566,
          567,
          568,
          569,
          570,
          571,
          572,
          573,
          574,
          575,
          576,
          577,
          578,
          579,
          580,
          581,
          582,
          583,
          584,
          585,
          586,
          587,
          588,
          589,
          590,
          591,
          592,
          593,
          594,
          595,
          596,
          597,
          598,
          599,
          600,
          601,
          602,
          603,
          604,
          605,
          606,
          607,
          608,
          609,
          610,
          611,
          612,
          613,
          614,
          615,
          616,
          617,
          618,
          619,
          620,
          621,
          622,
          623,
          624,
          625,
          626,
          627,
          628,
          629,
          630,
          631,
          632,
          633,
          634,
          635,
          636,
          637,
          638,
          639,
          640,
          641,
          642,
          643,
          644,
          645,
          646,
          647,
          648,
          649,
          650,
          651,
          652,
          653,
          654,
          655,
          656,
          657,
          658,
          659,
          660,
          661,
          662,
          663,
          664,
          665,
          666,
          667,
          668,
          669,
          670,
          671,
          672,
          673,
          674,
          675,
          676,
          677,
          678,
          679,
          680,
          681,
          682,
          683,
          684,
          685,
          686,
          687,
          688,
          689,
          690,
          691,
          692,
          693,
          694,
          695,
          696,
          697,
          698,
          699,
          700,
          701,
          702,
          703,
          704,
          705,
          706,
          707,
          708,
          709,
          710,
          711,
          712,
          713,
          714,
          715,
          716,
          717,
          718,
          719,
          720,
          721,
          722,
          723,
          724,
          725,
          726,
          727,
          728,
          729,
          730,
          731,
          732,
          733,
          734,
          735,
          736,
          737,
          738,
          739,
          740,
          741,
          742,
          743,
          744,
          745,
          746,
          747,
          748,
          749,
          750,
          751,
          752,
          753,
          754,
          755,
          756,
          757,
          758,
          759,
          760,
          761,
          762,
          763,
          764,
          765,
          766,
          767,
          768,
          769,
          770,
          771,
          772,
          773,
          774,
          775,
          776,
          777,
          778,
          779,
          780,
          781,
          782,
          783,
          784,
          785,
          786,
          787,
          788,
          789,
          790,
          791,
          792,
          793,
          794,
          795,
          796,
          797,
          798,
          799,
          800,
          801,
          802,
          803,
          804,
          805,
          806,
          807,
          808,
          809,
          810,
          811,
          812,
          813,
          814,
          815,
          816,
          817,
          818,
          819,
          820,
          821,
          822,
          823,
          824,
          825,
          826,
          827,
          828,
          829,
          830,
          831,
          832,
          833,
          834,
          835,
          836,
          837,
          838,
          839,
          840,
          841,
          842,
          843,
          844,
          845,
          846,
          847,
          848,
          849,
          850,
          851,
          852,
          853,
          854,
          855,
          856,
          857,
          858,
          859,
          860,
          861,
          862,
          863,
          864,
          865,
          866,
          867,
          868,
          869,
          870,
          871,
          872,
          873,
          874,
          875,
          876,
          877,
          878,
          879,
          880,
          881,
          882,
          883,
          884,
          885,
          886,
          887,
          888,
          889,
          890,
          891,
          892,
          893,
          894,
          895,
          896,
          897,
          898,
          899,
          900,
          901,
          902,
          903,
          904,
          905,
          906,
          907,
          908,
          909,
          910,
          911,
          912,
          913,
          914,
          915,
          916,
          917,
          918,
          919,
          920,
          921,
          922,
          923,
          924,
          925,
          926,
          927,
          928,
          929,
          930,
          931,
          932,
          933,
          934,
          935,
          936,
          937,
          938,
          939,
          940,
          941,
          942,
          943,
          944,
          945,
          946,
          947,
          948,
          949,
          950,
          951,
          952,
          953,
          954,
          955,
          956,
          957,
          958,
          959,
          960,
          961,
          962,
          963,
          964,
          965,
          966,
          967,
          968,
          969,
          970,
          971,
          972,
          973,
          974,
          975,
          976,
          977,
          978,
          979,
          980,
          981,
          982,
          983,
          984,
          985,
          986,
          987,
          988,
          989,
          990,
          991,
          992,
          993,
          994,
          995,
          996,
          997,
          998,
          999,
          1000,
          1001,
          1002,
          1003,
          1004,
          1005,
          1006,
          1007,
          1008,
          1009,
          1010,
          1011,
          1012,
          1013,
          1014,
          1015,
          1016,
          1017,
          1018,
          1019,
          1020,
          1021,
          1022,
          1023,
          1024,
          1025,
          1026,
          1027,
          1028,
          1029,
          1030,
          1031,
          1032,
          1033,
          1034,
          1035,
          1036,
          1037,
          1038,
          1039,
          1040,
          1041,
          1042,
          1043,
          1044,
          1045,
          1046,
          1047,
          1048,
          1049,
          1050,
          1051,
          1052,
          1053,
          1054,
          1055,
          1056,
          1057,
          1058,
          1059,
          1060,
          1061,
          1062,
          1063,
          1064,
          1065,
          1066,
          1067,
          1068,
          1069,
          1070,
          1071,
          1072,
          1073,
          1074,
          1075,
          1076,
          1077,
          1078,
          1079,
          1080,
          1081,
          1082,
          1083,
          1084,
          1085,
          1086,
          1087,
          1088,
          1089,
          1090,
          1091,
          1092,
          1093,
          1094,
          1095,
          1096,
          1097,
          1098,
          1099,
          1100,
          1101
         ],
         "y": [
          0.16905257038003563,
          0.053273442825567154,
          0.20201785953724472,
          0.33636908519299524,
          0.31065105262056664,
          0.4797809832186929,
          0.5647214588600368,
          0.46892691115651686,
          0.8193109947799272,
          0.8435665614609659,
          0.77911137873396,
          0.8742217815709401,
          0.9827164959288293,
          0.93754045098412,
          0.9612554554052632,
          0.8522067208249637,
          1.0550156337596448,
          1.0039784110353622,
          1.0011546686969084,
          0.7934390054772785,
          1.0740847659105413,
          0.8782829532453578,
          0.7693428552819379,
          0.9480922089454517,
          0.6703238294048642,
          0.45272443251345584,
          0.4742223929589764,
          0.19771989258597464,
          0.439032430897205,
          0.19664630876228723,
          0.06585678568404206,
          0.1477766453259196,
          -0.22456566614077497,
          -0.10530842227113964,
          -0.4630978222197084,
          -0.41811109534227375,
          -0.5640375606887494,
          -0.38470296184581854,
          -0.43626120506762867,
          -0.721667615921766,
          -0.6736156723646847,
          -0.8370746801517239,
          -0.8154674073103998,
          -0.9920334913882884,
          -1.1228937948177815,
          -1.1581607240057277,
          -0.9555526677869933,
          -0.7751822385754276,
          -0.9690796083228077,
          -1.0346016010860613,
          -0.7672397356913456,
          -0.9014289933851058,
          -0.8724831817104163,
          -0.8060113147932718,
          -0.7848379172586125,
          -0.7351641379237187,
          -0.7732880862528659,
          -0.4989076245119442,
          -0.4723360320253457,
          -0.2527104793813775,
          -0.3143418905534014,
          -0.37076383443278793,
          -0.09095372411924196,
          0.188905055129205,
          0.08036351574439288,
          0.12828777072512532,
          0.194309496498971,
          0.3019260401167415,
          0.46609873525946705,
          0.4623498772629432,
          0.8085393969214618,
          0.702352629491416,
          0.8060166319440086,
          0.995561106403132,
          1.0501383180932642,
          0.917605814848079,
          1.0017618466432805,
          1.0620682581231702,
          0.9793971086268444,
          0.8210131499014319,
          1.0544301940615792,
          1.0586519834250068,
          0.9813334824061799,
          0.808598851695675,
          0.8335125495724914,
          0.7376704354169459,
          0.7024421941648419,
          0.7904447428680704,
          0.7354505573128413,
          0.5653467630355189,
          0.46420853055402916,
          0.38383328839537845,
          0.21862132912551538,
          0.11375624617958927,
          -0.04577791923658174,
          -0.08395197077738284,
          0.04846117808301892,
          -0.1880228231699223,
          -0.4037828536709914,
          -0.5077130746315054,
          -0.6333141782915919,
          -0.5903051119949779,
          -0.6631880995918787,
          -0.9142330214742096,
          -0.7811675108990271,
          -0.9383317118556967,
          -0.7814833482779573,
          -0.9420019263510181,
          -0.8098688056779136,
          -1.0415950833702106,
          -1.0287651077288014,
          -0.9641720897354061,
          -0.8728043147477886,
          -0.8962746446387175,
          -1.0411518886711848,
          -0.8552694563918185,
          -0.8183608473337727,
          -0.8023133972812603,
          -0.7554453988074578,
          -0.44020020183302244,
          -0.5721710066347635,
          -0.5305685599264016,
          -0.2906498808006739,
          -0.2461406733146534,
          -0.16903453776110966,
          0.016041130473290567,
          0.08675838546669945,
          0.17372083893889667,
          0.33215307755974877,
          0.35997089785490666,
          0.3624737297269124,
          0.47625537093092385,
          0.5435799899196114,
          0.6938872123639205,
          0.635626196203653,
          0.6232586764577821,
          0.8703295937875002,
          0.7742610724406009,
          0.7500366234517593,
          1.0104379422639538,
          0.9201404385610106,
          1.0490882776542334,
          0.9446271334787796,
          0.873777468602826,
          0.8400249500697305,
          0.881644704991345,
          0.8652299484092805,
          0.7607287273016757,
          0.7570410140015262,
          0.5657683474344354,
          0.6478615755799758,
          0.3876187887423901,
          0.4625000576172476,
          0.4616990187118567,
          0.40732831948303094,
          0.3727564144240691,
          -0.053139295486880844,
          0.07850833330660634,
          0.023384022679857508,
          -0.09809621739586291,
          -0.3860308022295186,
          -0.345934713759145,
          -0.2912542634661884,
          -0.7123607721706535,
          -0.5947477554944351,
          -0.6044777776434221,
          -0.851535272520212,
          -0.7819309388164674,
          -0.997268044286669,
          -1.012450071511687,
          -1.0446768130717636,
          -0.9658494022443403,
          -1.0064404117109509,
          -0.9042210044883843,
          -1.0859559051667305,
          -0.9874332889048172,
          -0.8508342646682014,
          -0.8540324335224031,
          -0.9966428369633711,
          -0.7430864436007397,
          -0.794781898900159,
          -0.6382665157034814,
          -0.5698351867277863,
          -0.3950712986294742,
          -0.41727792348087517,
          -0.5219565624876683,
          -0.37783876845451136,
          -0.06960602559008883,
          -0.06899477220249503,
          0.1706246566914299,
          0.18359234284653103,
          0.17920135605376852,
          0.457667389841665,
          0.3605120058613486,
          0.32340145136429765,
          0.8171719570800899,
          0.49573793923869314,
          0.8196074770681909,
          0.9114462452109293,
          0.8856881917018989,
          0.7473539956894072,
          1.052751734588372,
          0.8331414063455411,
          0.8592070195745629,
          0.963742988250349,
          1.0751026761995057,
          1.0126450347723888,
          1.0402670889106438,
          0.881792081534917,
          0.86664421493475,
          0.7190176919963122,
          0.7415876331969197,
          0.7653982614077607,
          0.6018541514394231,
          0.5988170353315229,
          0.4078659236693633,
          0.3152252480130114,
          0.28390826863449586,
          0.1632307708635352,
          0.14285805764886123,
          0.001513104417328031,
          0.05794639050402729,
          -0.23664930680688018,
          -0.33389007376481333,
          -0.5085317031109498,
          -0.49155003065024383,
          -0.5099166533947758,
          -0.7308197344104335,
          -0.7337811386033078,
          -0.7216949719319982,
          -0.8630440252933453,
          -0.950567093424348,
          -0.8406591641605217,
          -0.9582034115661167,
          -0.9485082570225155,
          -0.8814045907340358,
          -0.8844076845989576,
          -1.0240671951242173,
          -1.0224053190825406,
          -0.9122499079036389,
          -0.9153726628119001,
          -1.0444736121665406,
          -0.6708013309239407,
          -0.732269261487587,
          -0.5890945745448246,
          -0.7019247108852841,
          -0.3718679598936939,
          -0.47056375267660633,
          -0.3294366009008938,
          -0.36255857833573446,
          -0.1406334874006385,
          -0.04720211684318382,
          0.05720119225557005,
          0.21878943543673707,
          0.27842614320872655,
          0.4646989259460573,
          0.4113633138134155,
          0.44505493120583184,
          0.6237775538727968,
          0.7633007581075796,
          0.8927003422997992,
          0.9097193513917725,
          0.7035921991708078,
          0.9608511650510172,
          1.1029615512621502,
          0.9873932987969574,
          0.9439328685537051,
          1.0309008362741892,
          0.9441098916390679,
          1.0428519503100262,
          0.9523598453186751,
          1.0581428534167536,
          0.9247896628370923,
          0.749700432653749,
          0.8215819316658158,
          0.7861398701270665,
          0.5601887007610566,
          0.49278104823090835,
          0.21781559050751917,
          0.44716530375225005,
          0.202972360960439,
          -0.04818112454555332,
          -0.11215760730978448,
          -0.05755680794877316,
          -0.058824587142699655,
          -0.24207714174715433,
          -0.2819416552180764,
          -0.5319274622585235,
          -0.6443550112594522,
          -0.5049859253237792,
          -0.621748459931246,
          -0.744710104421727,
          -0.6767308309623326,
          -0.9552918633748541,
          -0.9488317825133379,
          -0.8417337078285072,
          -0.7887148515548754,
          -0.9900517491401569,
          -0.8314349836488412,
          -1.0581382851316128,
          -0.9534352166859136,
          -0.982452968679205,
          -1.092906658659055,
          -0.8679563657341172,
          -0.7512143686825243,
          -0.8016081482301796,
          -0.7282524745238189,
          -0.5091287977133729,
          -0.6941242462867103,
          -0.6339524366277905,
          -0.4597970512245877,
          -0.4203116289347912,
          -0.06927060999471876,
          -0.07414213471487228,
          -0.09168091860738875,
          0.03317262162943023,
          0.4796733448921514,
          0.22956834362691994,
          0.3084802820168179,
          0.5053726366686735,
          0.6242776554827496,
          0.6625274301459222,
          0.6230008991677058,
          0.6643114929301807,
          0.8984098799807057,
          0.8835557761434535,
          0.7661221014671091,
          1.0793548933595327,
          1.0621560381632897,
          0.9730513574717167,
          0.9736741107125153,
          1.0154047543751568,
          0.9061950781192223,
          0.8129545384776112,
          0.9434509573540644,
          0.7215933460875463,
          0.8502238301489481,
          0.6045692987009528,
          0.6688222814458211,
          0.5884455323347118,
          0.6975205296232108,
          0.3248751211387901,
          0.19756225446566436,
          0.17879244859113724,
          0.032956555855014474,
          -0.01317990089604991,
          -0.012114901481202978,
          -0.07644673576300563,
          -0.08560162437151547,
          -0.4206232558707403,
          -0.17503102609260696,
          -0.32820727385547643,
          -0.6290559475974713,
          -0.914036639532546,
          -0.7625493642570159,
          -0.8087896482153452,
          -1.0996084513659767,
          -0.9072480407993769,
          -0.970449425032699,
          -1.0553050365205452,
          -0.9306050765313031,
          -0.8993361102677394,
          -1.0450944672228208,
          -0.9601713463276497,
          -1.0254114214503065,
          -1.0058078689554197,
          -0.8771426942362669,
          -0.7818457119490795,
          -0.8312720730680052,
          -0.929316459208281,
          -0.5752993000539929,
          -0.7131240742280739,
          -0.4553251164021418,
          -0.19900451824546053,
          -0.28420377289848964,
          -0.3042847267308374,
          -0.2323637295608219,
          0.13072655321117652,
          0.11177499395595762,
          0.2660986134462511,
          0.4012889468230338,
          0.397206432454239,
          0.4606736911006382,
          0.48131222114191075,
          0.3465498155409423,
          0.575206558707762,
          0.7849846372179314,
          0.831436956976829,
          0.9378500044576158,
          0.9243826465483411,
          0.9831753378515846,
          1.066536829374657,
          0.9098937855828575,
          0.9703413876250025,
          0.8290057733710227,
          1.0677904819853496,
          0.9454136381888133,
          0.952210447603547,
          1.0101020581283158,
          0.9078766295545704,
          0.7299922253662553,
          0.7434724486364835,
          0.44359904172715714,
          0.5463591539345825,
          0.4280290725053122,
          0.15934028278119453,
          0.35871713249240833,
          0.05614585643524288,
          0.0951795513384103,
          -0.11510223354183416,
          -0.07298889735553946,
          -0.13862829195171633,
          -0.44767257277239925,
          -0.6088745415165693,
          -0.5555850859687622,
          -0.5387382284146772,
          -0.7357115897833122,
          -0.8278984952887035,
          -0.7780194046131693,
          -1.155033679109027,
          -0.9886003383215973,
          -1.094535405114412,
          -0.9511413268329572,
          -1.0689098456170418,
          -1.1115125993275465,
          -1.0300914636968237,
          -1.126316163771437,
          -0.9557614401964405,
          -0.9881170379165517,
          -0.9138550751330526,
          -0.8953005795938911,
          -0.6715994906532116,
          -0.7053230874453511,
          -0.5666551765870143,
          -0.48960636428151033,
          -0.5313035200648295,
          -0.3022884317360061,
          -0.22937996174673414,
          -0.13528849759940173,
          -0.10721895328437482,
          -0.010056913322419966,
          0.21083359052613032,
          0.4488026673727749,
          0.24361660453004857,
          0.47283096499935817,
          0.47132450575251195,
          0.6699203247027699,
          0.7128374742354093,
          0.8459011554735357,
          0.5238948452818452,
          0.7987172899019432,
          0.806872351352397,
          0.9327019203416901,
          0.89949038313492,
          0.926438420084716,
          1.0674771521325825,
          1.1882478201983053,
          0.704456785829733,
          0.9347128137882333,
          0.9662250884131669,
          0.8954061700237951,
          0.8113845646508702,
          0.6530588648159052,
          0.628763100674039,
          0.7229240701268532,
          0.6788944074384478,
          0.4961656146274051,
          0.3131966887388505,
          0.312733269585078,
          0.18247529114508673,
          0.16229235548387305,
          0.019737278272578464,
          -0.15417517342453516,
          -0.17191268442349095,
          -0.40599472532992126,
          -0.30024723619493593,
          -0.3543871863095274,
          -0.6761179242215368,
          -0.5962278216505712,
          -0.8111414116779637,
          -0.6714103721731753,
          -0.7469459908095296,
          -0.9107824343253645,
          -0.8298017496283306,
          -1.0046432299796326,
          -1.0484602445559987,
          -1.0538163348150476,
          -1.0138466155454164,
          -1.0249238259521538,
          -0.9600450092652287,
          -1.0101289276138068,
          -0.8358122715482442,
          -0.7647223648365865,
          -0.8622760449132651,
          -0.893152254740372,
          -0.6082892003529099,
          -0.49025690023863305,
          -0.5378332521559256,
          -0.5623416959237942,
          -0.3148592499692327,
          -0.09349905778151224,
          -0.3355697827888724,
          -0.0006366648085039534,
          0.020199417650814247,
          0.06547205038626706,
          0.298825781018914,
          0.21459956467648306,
          0.46620946034516725,
          0.6555088491612697,
          0.6242788390844304,
          0.5953394550722805,
          0.5745739646607259,
          0.6863182771519287,
          0.6842572666218236,
          1.0735256616315627,
          0.9246627032020623,
          0.871648849320399,
          0.8631383447444392,
          0.8931005989608685,
          0.9631100604187303,
          0.8553371088813666,
          1.1282982994299497,
          0.8533927882065611,
          0.8080577504259762,
          0.8664143863249298,
          0.9216644475590277,
          0.842206206203616,
          0.5871322752268427,
          0.5812044629633081,
          0.4847829054344292,
          0.4323367060232875,
          0.3106187336563868,
          0.09351640566548582,
          -0.037147494890684654,
          0.006520768145630164,
          -0.22920447133569954,
          -0.07322585954991276,
          -0.30215759968714123,
          -0.5022996895694842,
          -0.5214004727940795,
          -0.6246211613168825,
          -0.6659298467815903,
          -0.6306093680199715,
          -0.9347746190299666,
          -1.0343249821543978,
          -0.8625233403319007,
          -0.9538559580460035,
          -0.9502445813570817,
          -0.9428876767143124,
          -1.0163505244719744,
          -0.9191991639623059,
          -1.0794006120711246,
          -0.9646955572306425,
          -1.0255325503011579,
          -1.0173468501358638,
          -0.7956691689704539,
          -0.7445957139550483,
          -0.9319722398539168,
          -0.7788707638534087,
          -0.5597033423246423,
          -0.39822140398897377,
          -0.48313181288537266,
          -0.34204325456924795,
          -0.36888724715713095,
          0.12191338314995487,
          0.018020669442938925,
          0.15994103741550442,
          0.23554830128446683,
          0.36063986909702567,
          0.42302034323818705,
          0.4199682907669862,
          0.6146291948475107,
          0.6294812520437794,
          0.8263495453031925,
          0.6912959989755018,
          0.7712362508363428,
          0.9437369140544615,
          1.0490703696243437,
          0.9698966661709877,
          0.9088501446463422,
          0.9831302125288006,
          0.9501775606250228,
          1.1846594497973049,
          1.0698741194406696,
          1.0816765082527389,
          0.951064848710017,
          0.8218685651804538,
          0.9424052811659498,
          0.9299224118093412,
          0.7545278434770935,
          0.6187489003248248,
          0.6479029527205667,
          0.4159283152660737,
          0.4381983908818009,
          0.19567356118948015,
          0.07221513945187055,
          0.12662370762739283,
          0.003800048329153795,
          0.06076535588261267,
          -0.2560518457422287,
          -0.32179218457424885,
          -0.5309858067036466,
          -0.692605563508769,
          -0.7673887196618963,
          -0.620733944796604,
          -0.8557767502306739,
          -0.689122271701263,
          -0.7152456519484262,
          -0.9331106540869681,
          -0.7767815007189756,
          -0.9485329119070566,
          -0.8776753025412494,
          -1.0217591073476966,
          -0.9022987719113822,
          -1.081594345624684,
          -0.9041700598684751,
          -0.9818728140164902,
          -0.9091618330330669,
          -0.7841290747275362,
          -0.7727531470134901,
          -0.7322861841268826,
          -0.5796477816021713,
          -0.49315883984829345,
          -0.6273000331924813,
          -0.34333752127210976,
          -0.23857278316065433,
          -0.28422951019688175,
          -0.07177191074591557,
          -0.14296640794065896,
          0.23330367682912256,
          0.1646266018935164,
          0.2776731364183226,
          0.49955064783399394,
          0.45602210801593046,
          0.6159675248224756,
          0.5315613242195796,
          0.653186456688823,
          0.6376762690582856,
          0.8150955992030975,
          0.9896518199639266,
          0.9506792047950654,
          1.0492345175529159,
          0.8810677816176932,
          0.908412246947167,
          0.9532613046005626,
          1.050156948377741,
          1.0116990991371768,
          0.9479248569438703,
          0.9756211787546186,
          0.8529907112661388,
          0.8120704611599627,
          0.8826577811009763,
          0.62397824444573,
          0.6244790537251661,
          0.6849500795143699,
          0.4462539854074705,
          0.4146668220672122,
          0.18785167532059507,
          0.3461954585124645,
          -0.1739013353368438,
          -0.16236258922565538,
          -0.25381774414701286,
          -0.08447181790999889,
          -0.30675876100685323,
          -0.46037473806035867,
          -0.6501122518363612,
          -0.5680994221424439,
          -0.6696406313320392,
          -0.8200632507548286,
          -0.9621348306703051,
          -0.9773451351343485,
          -0.8911459846034251,
          -0.9176806314310612,
          -0.9682754551318893,
          -1.0078020476921616,
          -1.1766460623674644,
          -0.9920280105127893,
          -1.0873236785214857,
          -0.9572171910818162,
          -0.882604630503537,
          -0.9551111056797158,
          -0.9393905229042392,
          -0.6789027263575198,
          -0.6764830695309101,
          -0.7016087746456546,
          -0.8578827823508536,
          -0.47709102331570186,
          -0.31887091827422276,
          -0.17541805202824493,
          -0.25827339166632346,
          -0.1557996688298839,
          -0.035881576946556984,
          0.19202288896080394,
          0.08949837408259695,
          0.29235257777647505,
          0.30469997376256863,
          0.513791310245167,
          0.4162614178313352,
          0.6884229217737631,
          0.6737121682444427,
          0.766310342252541,
          0.8987409918694685,
          1.009537974607115,
          0.7654988083865241,
          1.066243375598349,
          1.042736451220251,
          0.968616969057133,
          1.1396721073261222,
          1.009332007450543,
          1.1011023635646047,
          0.8840553426096891,
          0.8188060731939949,
          0.9810341324946595,
          1.0195016491791626,
          0.802929494211253,
          0.7577516093506756,
          0.5436401748719699,
          0.37500073662225275,
          0.3963336968594656,
          0.4761869321275033,
          0.04407257359238198,
          0.08224831579958203,
          -0.15932801151575468,
          -0.05702330221340291,
          -0.07972361527249416,
          -0.3890478854456231,
          -0.4006931271442429,
          -0.3185615750625328,
          -0.5468545751472117,
          -0.7434250102097855,
          -0.826424728930498,
          -0.9646148656201491,
          -0.7465417841802304,
          -0.9509671478034126,
          -0.8150084145345416,
          -0.8678957600375743,
          -1.0455793074368598,
          -1.047555153662444,
          -0.9221337350660888,
          -0.9802933550284316,
          -0.9537413309107134,
          -1.1207177484791981,
          -0.8321633383811216,
          -0.966175042768744,
          -1.0535157673564068,
          -0.8279163499085328,
          -0.6560216464635203,
          -0.413524988076139,
          -0.5793051424838076,
          -0.5883661893559481,
          -0.15185302363459513,
          -0.2533475078414266,
          -0.19796618974716057,
          -0.18020702190382615,
          -0.07303955830514505,
          0.27491853745651373,
          0.19840490359291377,
          0.26786142775886257,
          0.36360343081823854,
          0.6601883887430997,
          0.5282343022622652,
          0.727894648446982,
          0.7629461438727154,
          0.824149630674477,
          0.768388019632747,
          0.9692988735279766,
          1.102603923256539,
          0.9654036875586336,
          0.8978240900227247,
          0.8699414659779299,
          1.01744151785716,
          0.9604801481492387,
          0.9566746841944123,
          0.9380588589016209,
          0.7497113551455339,
          0.9268464254753641,
          0.815069330824933,
          0.7192003901810712,
          0.6776067088825359,
          0.6682510717255754,
          0.4964395676930853,
          0.31662382154713337,
          0.4248047957062115,
          0.16830202548494422,
          0.04042432212341221,
          -0.14302088451754108,
          -0.08595418994371323,
          -0.29056712803298945,
          -0.33491538837273865,
          -0.33244309240704795,
          -0.46464146506618786,
          -0.45225738969512513,
          -0.6037520419045671,
          -0.7486933033846691,
          -0.8082300832761494,
          -0.8852018627514713,
          -0.8206886467885673,
          -0.9251885635490451,
          -1.0011647615140797,
          -0.8987186894204076,
          -0.9868900991666426,
          -1.046416295037139,
          -1.1444494826602298,
          -0.9328789987702253,
          -0.9264070101770439,
          -0.909295138976992,
          -0.9128423940656551,
          -0.8990988683809661,
          -0.7765783858114144,
          -0.6613863543674112,
          -0.6210901941720935,
          -0.5404703032886041,
          -0.48525156811675485,
          -0.31259472208781086,
          -0.22770949810667412,
          -0.22838979828299838,
          0.022332454381168154,
          0.12543323402866366,
          0.2271857540821291,
          0.23083219890536655,
          0.32011268763710504,
          0.3158489866449424,
          0.5951523625412236,
          0.3888312575781716,
          0.6400156812584182,
          0.7150385272751865,
          0.8970663578754179,
          0.8656919036649127,
          0.8149588533084918,
          0.8052691292943864,
          0.9020942299745501,
          1.002981882440644,
          1.0052173295332012,
          0.9773461902213393,
          0.9161024431931059,
          0.9411050558648975,
          1.029857491394754,
          0.7787020593545312,
          0.8418868769043418,
          0.9417731853942065,
          0.7689448628989091,
          0.5943802248221983,
          0.6261339939721768,
          0.3992978933428671,
          0.38492433328620784,
          0.4455007349836584,
          0.38248795536268454,
          -0.07674193231957242,
          0.06423338991390037,
          0.08925125519160661,
          -0.25892461818621765,
          -0.27522878207244633,
          -0.24413010846083996,
          -0.5338846365666332,
          -0.5243629583073762,
          -0.6547240682838393,
          -0.9140911089921695,
          -0.7524789037371208,
          -0.8631699354663367,
          -0.801165471212498,
          -0.7249221287021455,
          -0.8968127919368528,
          -1.0232322509984801,
          -0.9529045985494816,
          -0.9791910737114891,
          -0.8885285978055812,
          -1.1162560777227943,
          -1.0608384552941756,
          -1.1111117781649151,
          -0.7992083630858409,
          -0.8065429450396028,
          -0.8053363541230334,
          -0.7431154764391266,
          -0.6503732538551832,
          -0.6025684313693913,
          -0.45346267434994303,
          -0.3780671778284228,
          -0.0936853098703963,
          -0.10206267217622708,
          -0.11661260895548249,
          0.006831636412562826,
          0.28444277594568024,
          0.307474754387457,
          0.38681163598714347,
          0.5208470260419187,
          0.6943955322357163,
          0.49569712535390326,
          0.6183331107647948,
          0.5873821800072567,
          0.8718625686934123,
          0.8372004910325428,
          0.8518556194472018,
          0.8775872643410547,
          1.0481785895076967,
          0.9802788079112497,
          0.9469351667243355,
          1.1210256990945024,
          0.8764312476241993,
          0.8303406639664311,
          1.182416857527367,
          0.8431247939466123,
          0.7736988758170347,
          0.6951728320211445,
          0.6864162785101512,
          0.703571113970738,
          0.6195819642067688,
          0.5121388695930278,
          0.33879367247815195,
          0.122901372230459,
          0.2027405164834271,
          0.22711665097794537,
          0.0822045432620288,
          -0.14126220190786304,
          -0.14265150199324403,
          -0.3576946412619894,
          -0.4177094692674837,
          -0.6245590698951373,
          -0.6165828433609123,
          -0.6490514776593469,
          -0.7514501566656342,
          -0.7216432481119225,
          -0.6663806054681498,
          -0.7701465542197621,
          -0.9713461960872476,
          -1.0431027788854503,
          -1.054685661129371,
          -1.0967421524957803,
          -0.9951154067114136,
          -0.9459757502857372,
          -0.9494751999888331,
          -0.9184293951017592,
          -0.8826131353243872,
          -0.8632943884685823,
          -0.8674808572229105,
          -0.556005679616901,
          -0.5516585686552232,
          -0.6686156875680549,
          -0.5839156240272526,
          -0.462686716829667,
          -0.3073850583646211,
          -0.08830517722481618,
          -0.01410519797829321,
          0.09096079702306162,
          0.19290293594310698,
          0.2938524311467422,
          0.3541420045206733,
          0.420379962936821,
          0.45373201786168066,
          0.37731280921303656,
          0.6193035649595794,
          0.8866384298688487,
          0.7195955904364356,
          0.7704397362886497,
          0.9858386748243839,
          0.9344080588150603,
          0.9113267135020964,
          1.13849293658875,
          1.0587110770658024,
          1.0756607488958652,
          0.937055402179043,
          1.0268945162031904,
          0.98874466594664,
          0.9931997256443731,
          0.9856519446743521,
          0.9298793900087989,
          0.7726867292845958,
          0.7553979871744241,
          0.49588724264234135,
          0.5926002498684652,
          0.5092329577062324,
          0.3100711290211362,
          0.1762478364585522,
          0.14987712628058922,
          -0.06501950307306348,
          -0.009576342756777802,
          -0.11374793979571363,
          -0.33619650318763616,
          -0.33229164487223045,
          -0.32261584075453076,
          -0.41117159102812467,
          -0.4992504858655599,
          -0.6922104475308009,
          -0.7810869593033974,
          -0.8489875098533158,
          -0.8051630944785224,
          -0.6751312127766543,
          -0.80660263463564,
          -0.8158413204974488,
          -0.8570010431895141,
          -1.1609224919239598,
          -1.0173775283234705,
          -1.0282581344627868,
          -0.8378756186687569,
          -0.762207663222757,
          -0.9563418574306491,
          -0.836089764824922,
          -0.725845614027109,
          -0.7642019734141114,
          -0.7048490843386092,
          -0.6299624643032757,
          -0.3883300599201557,
          -0.47756354720611277,
          -0.17908693125872152,
          -0.18697476561688392,
          -0.0215780716854502,
          0.15764134823264614,
          0.03609589744157424,
          0.12014201817774364,
          0.34128676719734746,
          0.28926722210698885,
          0.40932269029566715,
          0.5560494094081384,
          0.6624812013229158,
          0.5953897446952587,
          0.7472502333114583,
          0.9015853264647242,
          1.0270937837581755,
          0.7373813032595474,
          1.0948871396852349,
          1.0740511906119277,
          0.889472592734238,
          0.8527817176131597,
          1.0328201415298994,
          0.9311509760652851,
          0.9586412946775337,
          0.9935226895608272,
          0.8241706618941503,
          0.8223856537153676,
          0.7904455712794304,
          0.7611317896752656,
          0.7707945373070353,
          0.6815025515579352,
          0.4477338271112723,
          0.30761201789273573,
          0.4715833699463414,
          0.20078855251166405,
          0.0799545422231146,
          -0.17217807382253283,
          -0.08442592173848774,
          -0.3369950316403214,
          -0.40038265850169097,
          -0.5792695829450476,
          -0.5851528098759258,
          -0.6091331618855605,
          -0.8402466767746786,
          -0.8487496503327346,
          -0.8286017683455698,
          -0.9994274781800826,
          -1.0425595118342037,
          -1.035753491686308,
          -1.1184955458751964,
          -0.9330488683927338,
          -1.0988094466425713,
          -0.9191435246527553,
          -0.8894545948340049,
          -1.0767570677373688,
          -0.9198865706511904,
          -0.9287909042555504,
          -0.9427260678724605,
          -0.8029164565100383,
          -0.7260007580127815,
          -0.5565324947692292,
          -0.444282736590232,
          -0.5696728233882029,
          -0.4095486482204212,
          -0.22158234176123637,
          -0.05965864574873514,
          -0.3212739201384991,
          0.1495544424047029,
          0.1050843631655375,
          0.37315345228194097,
          0.27439670421409346,
          0.3269315664718445,
          0.5033261107551208,
          0.6995582733739337,
          0.6641937156964556,
          0.49756224918820374,
          0.8653141971374316,
          0.6927772330941265,
          0.8035332043389178,
          0.8240263884701184,
          0.7858931913335847,
          0.8639926547672595,
          0.9002541530260276,
          0.9375337013149057,
          0.9831643769841119,
          0.9350412571603074,
          0.7906658725694493,
          0.8814184206824626,
          0.9487477979423676,
          0.8896685037330584,
          0.7437387031909799,
          0.7203366298083907,
          0.6691653480309979,
          0.631847661069189,
          0.5761143978144703,
          0.2811644073468362,
          0.1896179488676797,
          0.2654875117421198,
          0.1745567590191609,
          0.07257294375748316,
          -0.41497625608739463
         ]
        },
        {
         "hovertemplate": "$%{y:.2f}",
         "line": {
          "color": "yellow"
         },
         "mode": "lines",
         "name": "Future",
         "type": "scatter",
         "x": [
          1102,
          1103,
          1104,
          1105,
          1106,
          1107,
          1108,
          1109,
          1110,
          1111,
          1112,
          1113,
          1114,
          1115,
          1116,
          1117,
          1118,
          1119,
          1120,
          1121,
          1122,
          1123,
          1124,
          1125,
          1126,
          1127,
          1128,
          1129,
          1130,
          1131,
          1132,
          1133,
          1134,
          1135,
          1136,
          1137,
          1138,
          1139,
          1140,
          1141,
          1142,
          1143,
          1144,
          1145,
          1146,
          1147,
          1148,
          1149,
          1150,
          1151,
          1152,
          1153,
          1154,
          1155,
          1156,
          1157,
          1158,
          1159,
          1160,
          1161,
          1162,
          1163,
          1164,
          1165,
          1166,
          1167,
          1168,
          1169,
          1170,
          1171,
          1172,
          1173,
          1174,
          1175,
          1176,
          1177,
          1178,
          1179,
          1180,
          1181,
          1182,
          1183,
          1184,
          1185,
          1186,
          1187,
          1188,
          1189,
          1190,
          1191,
          1192,
          1193,
          1194,
          1195,
          1196,
          1197,
          1198,
          1199,
          1200,
          1201,
          1202,
          1203,
          1204,
          1205,
          1206,
          1207,
          1208,
          1209,
          1210,
          1211,
          1212,
          1213,
          1214,
          1215,
          1216,
          1217,
          1218,
          1219,
          1220,
          1221,
          1222,
          1223,
          1224,
          1225,
          1226,
          1227,
          1228,
          1229
         ],
         "y": [
          -0.29991099381894704,
          -0.6980362816026616,
          -0.3903096004498441,
          -0.5439277466410546,
          -0.6249634492044108,
          -0.7183421219861874,
          -0.6415821247474176,
          -0.8608585601316036,
          -0.7795509093445712,
          -0.8699897121565459,
          -0.9229030604258479,
          -0.9359758672797105,
          -0.9849947135753705,
          -1.1093087562539687,
          -0.9221872767326743,
          -0.9064128791042659,
          -0.966294695439801,
          -0.8434782143650561,
          -0.7821352259655604,
          -0.9469411473582434,
          -0.7715750036900237,
          -0.7326872366829813,
          -0.7029967558399248,
          -0.49824382070103523,
          -0.5274836082446089,
          -0.3948636834220002,
          -0.23163148635541217,
          -0.12337095155747224,
          -0.026802622241579088,
          0.26442178357528257,
          0.09024019852939236,
          0.2637996195129636,
          0.21398125011373192,
          0.47514074365144765,
          0.6305206439644109,
          0.7195804621089591,
          0.6116514399224487,
          0.7175730620406142,
          0.934591151992211,
          0.8537657698432982,
          1.0050912325411185,
          0.8490116348223753,
          1.112159797881372,
          1.0943799178515266,
          1.0459769520101587,
          0.9176419081281553,
          0.9694741459519297,
          0.9786680638189189,
          0.9583460264222855,
          0.8806711840736264,
          0.819539444737399,
          0.8024504062077853,
          0.8567516293724571,
          0.4432274716192148,
          0.4272091154194746,
          0.3246467483991945,
          0.3203834325801808,
          0.12111208229172071,
          0.2535560633138905,
          0.10893997563442548,
          -0.0258794724881205,
          -0.1685207208397813,
          -0.1835417829294424,
          -0.2782717747431682,
          -0.35697912122737663,
          -0.5529161346034467,
          -0.5002931561307724,
          -0.7916382504587435,
          -0.5929509531318319,
          -1.0915004679378275,
          -0.9012903002766726,
          -1.011833121673926,
          -0.8533936586624656,
          -1.112325256561414,
          -0.8034309223449798,
          -1.152024588508206,
          -0.7966965611500612,
          -0.9467245982671195,
          -0.9705223412978278,
          -0.9023502107610587,
          -0.6895477082852595,
          -0.7732876728623774,
          -1.0310992494871514,
          -0.6254278440405295,
          -0.6513144178588484,
          -0.7590922616753936,
          -0.4382666680596194,
          -0.5472082975056285,
          -0.3155005082049204,
          -0.21448212484062557,
          -0.20445511556895218,
          0.024728227695651514,
          -0.0422012248991991,
          0.17846493082222933,
          0.20240973040655877,
          0.3340982084529594,
          0.6363542832351982,
          0.5425300986332336,
          0.5045364375112652,
          0.6773669137222474,
          0.6810900076029436,
          0.8220125558369757,
          0.8887113778576393,
          0.9254482327966379,
          0.9605943021356225,
          0.9235097918142481,
          1.03884049984845,
          1.10568278646334,
          0.9339304797161745,
          0.976206584714425,
          0.9643681623074288,
          1.0503435367228862,
          0.9903243511110171,
          0.7579852704992102,
          0.7785163873473133,
          0.5544619548318068,
          0.5328528684317653,
          0.5501529539262826,
          0.5254074549221316,
          0.4669928201955146,
          0.24589806696822047,
          0.044338869408862946,
          0.12018127850979826,
          -0.03675703687383812,
          -0.07680800025166336,
          -0.20175077215016934,
          -0.24257224295297192,
          -0.3419230666464081
         ]
        },
        {
         "hovertemplate": "$%{y:.2f}",
         "line": {
          "color": "red"
         },
         "mode": "lines",
         "name": "Forecasted",
         "type": "scatter",
         "x": [
          1102,
          1103,
          1104,
          1105,
          1106,
          1107,
          1108,
          1109,
          1110,
          1111,
          1112,
          1113,
          1114,
          1115,
          1116,
          1117,
          1118,
          1119,
          1120,
          1121,
          1122,
          1123,
          1124,
          1125,
          1126,
          1127,
          1128,
          1129,
          1130,
          1131,
          1132,
          1133,
          1134,
          1135,
          1136,
          1137,
          1138,
          1139,
          1140,
          1141,
          1142,
          1143,
          1144,
          1145,
          1146,
          1147,
          1148,
          1149,
          1150,
          1151,
          1152,
          1153,
          1154,
          1155,
          1156,
          1157,
          1158,
          1159,
          1160,
          1161,
          1162,
          1163,
          1164,
          1165,
          1166,
          1167,
          1168,
          1169,
          1170,
          1171,
          1172,
          1173,
          1174,
          1175,
          1176,
          1177,
          1178,
          1179,
          1180,
          1181,
          1182,
          1183,
          1184,
          1185,
          1186,
          1187,
          1188,
          1189,
          1190,
          1191,
          1192,
          1193,
          1194,
          1195,
          1196,
          1197,
          1198,
          1199,
          1200,
          1201,
          1202,
          1203,
          1204,
          1205,
          1206,
          1207,
          1208,
          1209,
          1210,
          1211,
          1212,
          1213,
          1214,
          1215,
          1216,
          1217,
          1218,
          1219,
          1220,
          1221,
          1222,
          1223,
          1224,
          1225,
          1226,
          1227,
          1228,
          1229,
          1230,
          1231,
          1232,
          1233,
          1234,
          1235,
          1236,
          1237,
          1238,
          1239,
          1240,
          1241,
          1242,
          1243,
          1244,
          1245,
          1246,
          1247,
          1248,
          1249,
          1250,
          1251,
          1252,
          1253,
          1254,
          1255,
          1256,
          1257,
          1258,
          1259,
          1260,
          1261,
          1262,
          1263,
          1264,
          1265,
          1266,
          1267,
          1268,
          1269,
          1270,
          1271,
          1272,
          1273,
          1274,
          1275,
          1276,
          1277,
          1278,
          1279,
          1280,
          1281,
          1282,
          1283,
          1284,
          1285,
          1286,
          1287,
          1288,
          1289,
          1290,
          1291,
          1292,
          1293,
          1294,
          1295,
          1296,
          1297,
          1298,
          1299,
          1300,
          1301,
          1302,
          1303,
          1304,
          1305,
          1306,
          1307,
          1308,
          1309,
          1310,
          1311,
          1312,
          1313,
          1314,
          1315,
          1316,
          1317,
          1318,
          1319,
          1320,
          1321,
          1322,
          1323,
          1324,
          1325,
          1326,
          1327,
          1328,
          1329
         ],
         "y": [
          -0.5006428360939026,
          -0.538101851940155,
          -0.5274183750152588,
          -0.5162978768348694,
          -0.5308117270469666,
          -0.5764030814170837,
          -0.623249351978302,
          -0.636525571346283,
          -0.6171633005142212,
          -0.5901756882667542,
          -0.5762696862220764,
          -0.5875615477561951,
          -0.6203639507293701,
          -0.6556552052497864,
          -0.6802275776863098,
          -0.6840892434120178,
          -0.6710203886032104,
          -0.6505904793739319,
          -0.6290448307991028,
          -0.6045481562614441,
          -0.5708410143852234,
          -0.5285839438438416,
          -0.49346643686294556,
          -0.4695448875427246,
          -0.4543272852897644,
          -0.4399617612361908,
          -0.4131565988063812,
          -0.36901822686195374,
          -0.3077476918697357,
          -0.24673247337341309,
          -0.1985681653022766,
          -0.16766703128814697,
          -0.16052624583244324,
          -0.18616566061973572,
          -0.25706687569618225,
          -0.36758700013160706,
          -0.4791160225868225,
          -0.5408632159233093,
          -0.5363462567329407,
          -0.48525217175483704,
          -0.43844321370124817,
          -0.4492766261100769,
          -0.5152785181999207,
          -0.587064802646637,
          -0.6274396777153015,
          -0.6272498965263367,
          -0.6088505983352661,
          -0.6067953705787659,
          -0.6228622198104858,
          -0.6446038484573364,
          -0.6425924897193909,
          -0.603276789188385,
          -0.5358902812004089,
          -0.4744643270969391,
          -0.4474959373474121,
          -0.4605953097343445,
          -0.4932337999343872,
          -0.5033161044120789,
          -0.4723690450191498,
          -0.4098813533782959,
          -0.3336678147315979,
          -0.25712329149246216,
          -0.18237870931625366,
          -0.11432057619094849,
          -0.06031442806124687,
          -0.039350252598524094,
          -0.05313539132475853,
          -0.08454160392284393,
          -0.10632459819316864,
          -0.08964814245700836,
          -0.015207243151962757,
          0.11473655700683594,
          0.26014444231987,
          0.3697147071361542,
          0.4389612674713135,
          0.4932176470756531,
          0.5501105189323425,
          0.6073540449142456,
          0.6565974354743958,
          0.687360405921936,
          0.7014464735984802,
          0.6913743019104004,
          0.6583771109580994,
          0.6216830611228943,
          0.5889108180999756,
          0.5632091760635376,
          0.5524007678031921,
          0.5541926026344299,
          0.5708708167076111,
          0.5894671678543091,
          0.5994686484336853,
          0.5911414623260498,
          0.5623505115509033,
          0.5300608277320862,
          0.520355224609375,
          0.5370351672172546,
          0.5610650181770325,
          0.5743755102157593,
          0.565856397151947,
          0.5320174098014832,
          0.48614588379859924,
          0.44604942202568054,
          0.41328126192092896,
          0.3766708970069885,
          0.31853312253952026,
          0.24048279225826263,
          0.15150317549705505,
          0.06300599873065948,
          -0.00571694690734148,
          -0.05213221535086632,
          -0.10189218819141388,
          -0.15391814708709717,
          -0.1982298195362091,
          -0.23167367279529572,
          -0.2606296241283417,
          -0.27280759811401367,
          -0.2800925374031067,
          -0.29218798875808716,
          -0.3077191114425659,
          -0.3204388916492462,
          -0.3372027277946472,
          -0.38353127241134644,
          -0.4791520833969116,
          -0.6028713583946228,
          -0.7137272953987122,
          -0.7798078060150146,
          -0.8040788173675537,
          -0.8007575869560242,
          -0.7877973914146423,
          -0.7844669222831726,
          -0.8040364384651184,
          -0.8388369679450989,
          -0.8633183836936951,
          -0.8740442991256714,
          -0.8851040005683899,
          -0.8991551995277405,
          -0.910495936870575,
          -0.9091081023216248,
          -0.8957996964454651,
          -0.8760685324668884,
          -0.8666800856590271,
          -0.879353940486908,
          -0.9167773127555847,
          -0.9574606418609619,
          -0.9743223786354065,
          -0.9685311317443848,
          -0.9386621117591858,
          -0.9081782698631287,
          -0.9020591378211975,
          -0.9168153405189514,
          -0.9332979917526245,
          -0.9298887848854065,
          -0.8976446390151978,
          -0.8377750515937805,
          -0.7687793970108032,
          -0.7181575894355774,
          -0.7025673389434814,
          -0.7142624258995056,
          -0.7264907360076904,
          -0.7174741625785828,
          -0.695196270942688,
          -0.6758167147636414,
          -0.6594492197036743,
          -0.6423609852790833,
          -0.6321312785148621,
          -0.6385231614112854,
          -0.6710496544837952,
          -0.7151467800140381,
          -0.7667320966720581,
          -0.8124012351036072,
          -0.8523317575454712,
          -0.887791097164154,
          -0.9133493304252625,
          -0.9290050268173218,
          -0.9281671643257141,
          -0.913539707660675,
          -0.8899811506271362,
          -0.8632983565330505,
          -0.850079357624054,
          -0.8610584139823914,
          -0.8862617015838623,
          -0.8981019854545593,
          -0.8841765522956848,
          -0.8578312993049622,
          -0.8296636939048767,
          -0.8176299333572388,
          -0.8266295790672302,
          -0.8493676781654358,
          -0.8729436993598938,
          -0.8697867393493652,
          -0.8371001482009888,
          -0.7963297367095947,
          -0.7717785239219666,
          -0.7551037669181824,
          -0.7325062155723572,
          -0.6849690079689026,
          -0.6087306141853333,
          -0.5299708843231201,
          -0.5025463104248047,
          -0.546779453754425,
          -0.6286451816558838,
          -0.7088682651519775,
          -0.7589935660362244,
          -0.7544369101524353,
          -0.7118248343467712,
          -0.6648178696632385,
          -0.6373409628868103,
          -0.630642294883728,
          -0.6291444897651672,
          -0.6176885366439819,
          -0.5966015458106995,
          -0.5696133375167847,
          -0.5289618372917175,
          -0.47214120626449585,
          -0.4000835716724396,
          -0.31534847617149353,
          -0.2346709966659546,
          -0.17069695889949799,
          -0.12368746101856232,
          -0.08109772205352783,
          -0.025284793227910995,
          0.046878766268491745,
          0.11805205047130585,
          0.16360463201999664,
          0.1821029633283615,
          0.19726940989494324,
          0.24035264551639557,
          0.33604228496551514
         ]
        }
       ],
       "layout": {
        "hovermode": "x unified",
        "legend": {
         "orientation": "h",
         "x": 0.9,
         "xanchor": "right",
         "y": 1.02,
         "yanchor": "bottom"
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#f2f5fa"
            },
            "error_y": {
             "color": "#f2f5fa"
            },
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "baxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#506784"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "header": {
             "fill": {
              "color": "#2a3f5f"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#f2f5fa",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#f2f5fa"
          },
          "geo": {
           "bgcolor": "rgb(17,17,17)",
           "lakecolor": "rgb(17,17,17)",
           "landcolor": "rgb(17,17,17)",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#506784"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "dark"
          },
          "paper_bgcolor": "rgb(17,17,17)",
          "plot_bgcolor": "rgb(17,17,17)",
          "polar": {
           "angularaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "radialaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "yaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "zaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#f2f5fa"
           }
          },
          "sliderdefaults": {
           "bgcolor": "#C8D4E3",
           "bordercolor": "rgb(17,17,17)",
           "borderwidth": 1,
           "tickwidth": 0
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "caxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "updatemenudefaults": {
           "bgcolor": "#506784",
           "borderwidth": 0
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "rangeselector": {
          "font": {
           "color": "black"
          }
         }
        },
        "yaxis": {
         "fixedrange": true
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "last_train_values = train_set.Elec_kW.values[-input_len:]\n",
    "next_validation_values = valid_set.Elec_kW.values[:fh]\n",
    "pred_y = exp.predict(last_train_values, fh+100)\n",
    "exp.print_metrics(next_validation_values, pred_y[:fh])\n",
    "plot_predictions(train_set.Elec_kW.values, next_validation_values, pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### SimpleTransformer (Local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from models.transformer import TimeSeriesTransformer\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "#\n",
    "from layers import PositionalEmbedding,Time2Vec\n",
    "\n",
    "class TimeSeriesTransformer(nn.Module):\n",
    "    def __init__(self, model_params: dict):\n",
    "        super(TimeSeriesTransformer, self).__init__()\n",
    "        # Set model vars\n",
    "        expected_vars = ['in_features','d_model','input_len','max_input_len',\n",
    "                         'encoder_nheads','encoder_nlayers','encoder_dropout',\n",
    "                         'decoder_nheads','decoder_nlayers','decoder_dropout',\n",
    "                         'feedforward_dim','forecast_horizon','seed','time_emb_dim','verbose']\n",
    "        for v in expected_vars:\n",
    "            assert v in model_params.keys(), f'Key \"{v}\" is missing on params dict'\n",
    "            vars(self)[v] = model_params[v]\n",
    "        #\n",
    "        # Pre-configuration (to produce same result in inference/predict)\n",
    "        #\n",
    "        np.random.seed(self.seed)\n",
    "        torch.manual_seed(self.seed)\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.manual_seed_all(self.seed)\n",
    "        #\n",
    "        self.train_loss_history = []\n",
    "        self.validation_loss_history = []\n",
    "        #\n",
    "        # Encoder layers\n",
    "        #\n",
    "        self.encoder_input_layer = nn.Linear(in_features=self.in_features, out_features=self.d_model)\n",
    "        self.positional_encoding = Time2Vec(input_dim=self.d_model, embed_dim=self.time_emb_dim * self.d_model)#PositionalEmbedding(self.d_model, max_len=self.max_input_len)\n",
    "        \n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "                            d_model=self.d_model,\n",
    "                            nhead=self.encoder_nheads,\n",
    "                            dim_feedforward=self.feedforward_dim,\n",
    "                            dropout=self.encoder_dropout,\n",
    "                            batch_first=True)\n",
    "        self.encoder_block = nn.TransformerEncoder(encoder_layer=encoder_layer, num_layers=self.encoder_nlayers, norm=None)\n",
    "        #\n",
    "        # Decoder layers\n",
    "        #\n",
    "        self.decoder_input_layer = nn.Linear(in_features=self.in_features, out_features=self.d_model)\n",
    "        decoder_layer = nn.TransformerDecoderLayer(\n",
    "                            d_model=self.d_model, \n",
    "                            nhead=self.decoder_nheads,\n",
    "                            dim_feedforward=self.feedforward_dim,\n",
    "                            dropout=self.decoder_dropout,\n",
    "                            batch_first=True,\n",
    "                            )\n",
    "        self.decoder_block = nn.TransformerDecoder(decoder_layer=decoder_layer,num_layers=self.decoder_nlayers, norm=None)\n",
    "        self.decoder_dense_mapping = nn.Linear(self.d_model, self.in_features)\n",
    "\n",
    "    def get_train_masks(self,):\n",
    "        # which will mask the encoder output\n",
    "        memory_mask = generate_square_subsequent_mask(self.forecast_horizon, self.input_len)\n",
    "        # which will mask the decoder input\n",
    "        tgt_mask = generate_square_subsequent_mask(self.forecast_horizon, self.forecast_horizon)\n",
    "        return memory_mask, tgt_mask\n",
    "\n",
    "    def encode(self, x):\n",
    "        if self.verbose: print(f'#1) Encoder input shape = {x.shape}')\n",
    "        \n",
    "        # linear transformation (embedding)\n",
    "        y = self.encoder_input_layer(x)\n",
    "        \n",
    "        if self.verbose: print(f'#2) Encoder embedding layer output: {y.shape}')\n",
    "        \n",
    "        # # positional encoding \n",
    "        y = self.positional_encoding(y)\n",
    "        if self.verbose: print(f'#3) Positional encoding output: {y.shape}')\n",
    "\n",
    "        # encoder block \n",
    "        y = self.encoder_block(y)\n",
    "        if self.verbose: print(f'#4) Encoder block output: {y.shape}\\n')\n",
    "        return y\n",
    "    \n",
    "    def decode(self, x, enc_y,  memory_mask, tgt_mask):\n",
    "        if self.verbose: print(f'#5) Decoder input shape = {x.shape}')\n",
    "        y = self.decoder_input_layer(x)\n",
    "        if self.verbose: print(f'#6) Decoder input layer output: {y.shape}')\n",
    "        \n",
    "        # positional encoding \n",
    "        y = self.positional_encoding(y)\n",
    "        if self.verbose: print(f'#7) Positional encoding output: {y.shape}')\n",
    "        \n",
    "        # Pass decoder input through decoder input layer\n",
    "        y = self.decoder_block(\n",
    "            tgt=y,\n",
    "            memory=enc_y,\n",
    "            tgt_mask=tgt_mask,\n",
    "            memory_mask=memory_mask\n",
    "        )\n",
    "        if self.verbose: print(f'#8) Decoder block output: {y.shape}')\n",
    "\n",
    "        # mapping (dense)\n",
    "        y = self.decoder_dense_mapping(y)\n",
    "        # y = self.decoder_dense_mapping2(y)\n",
    "        if self.verbose: print(f'#9) Decoder mapping(dense) output: {y.shape}')\n",
    "\n",
    "        return y\n",
    "\n",
    "    def forward(self, enc_x, dec_x, memory_mask=None, tgt_mask=None):\n",
    "        enc_y = self.encode(enc_x)\n",
    "        dec_y = self.decode(dec_x, enc_y, memory_mask, tgt_mask)\n",
    "        return dec_y\n",
    "    \n",
    "    def is_transformer(self,):\n",
    "        return True\n",
    "    \n",
    "    def predict(self, src, forecast_horizon):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            output = torch.zeros(1, forecast_horizon + 1, 1).to('cuda')\n",
    "            output[0, 0, 0] = src[0, -1] # first value\n",
    "            for i in range(forecast_horizon):\n",
    "                dim_a = output.shape[1]\n",
    "                tgt_mask = generate_square_subsequent_mask(dim_a, dim_a).to('cuda')\n",
    "                y = self(src, output, None, tgt_mask)[0,i,0]\n",
    "                output[0,i+1,0] = y\n",
    "        return output[:,1:,:] # remove first value (copy from last history step)\n",
    "\n",
    "    def validate(self, data):\n",
    "        val_loader = DataLoader(data, batch_size=1024, shuffle=False)\n",
    "        loss_fn = nn.MSELoss()\n",
    "        val_loss = 0.0\n",
    "        #\n",
    "        memory_mask, tgt_mask = self.get_train_masks()\n",
    "        memory_mask, tgt_mask = memory_mask.to('cuda'), tgt_mask.to('cuda')\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            for enc_x, dec_x, tgt_y in val_loader:\n",
    "                pred_y = self(enc_x, dec_x, memory_mask, tgt_mask)\n",
    "                val_loss += loss_fn(pred_y, tgt_y)\n",
    "        val_loss = val_loss/len(val_loader)\n",
    "        return val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of weights: 9137\n"
     ]
    }
   ],
   "source": [
    "input_len = 50 \n",
    "fh = 128\n",
    "d_model = 16\n",
    "model_params = {\n",
    "        'in_features':1, # The number of input variables. 1 if univariate forecasting.\n",
    "        'input_len':input_len,\n",
    "        'max_input_len':fh*10, # What's the longest sequence the model will encounter? Used to make the positional encoder\n",
    "        'forecast_horizon':fh, # Length of the target sequence, i.e. how many time steps should your forecast cover\n",
    "        #\n",
    "        'd_model':d_model, # model embedding dimension This can be any value divisible by n_heads. 512 is used in the original transformer paper.\n",
    "        'feedforward_dim':16,\n",
    "        'time_emb_dim':1,\n",
    "        #\n",
    "        'encoder_nheads':2, # The number of attention heads (parallel attention layers)\n",
    "        'decoder_nheads':2, # The number of attention heads (parallel attention layers)\n",
    "        'encoder_nlayers':2, # Number of times the layer is stacked\n",
    "        'decoder_nlayers':2, # Number of times the layer is stacked\n",
    "        #\n",
    "        'encoder_dropout': 0, #0.1,\n",
    "        'decoder_dropout': 0,# 0.1, # with zeroed dropout we can reproduce the outputs.\n",
    "        'encoder_ps_dropout': 0,#0.1,\n",
    "        'seed':7,\n",
    "        'verbose':False,\n",
    "    }\n",
    "model = TimeSeriesTransformer(model_params)\n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print('Num of weights:',pytorch_total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler FIT\n",
      "Epoch 1/1024 [0.190secs] -> Train loss: 0.97497 | Validation loss: 0.65007\n",
      "Epoch 2/1024 [0.144secs] -> Train loss: 0.65007 | Validation loss: 0.52344\n",
      "Epoch 3/1024 [0.138secs] -> Train loss: 0.52344 | Validation loss: 0.27900\n",
      "Epoch 4/1024 [0.137secs] -> Train loss: 0.27900 | Validation loss: 0.18774\n",
      "Epoch 5/1024 [0.137secs] -> Train loss: 0.18774 | Validation loss: 0.21685\n",
      "Epoch 6/1024 [0.137secs] -> Train loss: 0.21685 | Validation loss: 0.26696\n",
      "Epoch 7/1024 [0.136secs] -> Train loss: 0.26696 | Validation loss: 0.27692\n",
      "Epoch 8/1024 [0.138secs] -> Train loss: 0.27692 | Validation loss: 0.24888\n",
      "Epoch 9/1024 [0.136secs] -> Train loss: 0.24888 | Validation loss: 0.21091\n",
      "Epoch 10/1024 [0.138secs] -> Train loss: 0.21091 | Validation loss: 0.18703\n",
      "Epoch 11/1024 [0.138secs] -> Train loss: 0.18703 | Validation loss: 0.18544\n",
      "Epoch 12/1024 [0.139secs] -> Train loss: 0.18544 | Validation loss: 0.19908\n",
      "Epoch 13/1024 [0.138secs] -> Train loss: 0.19908 | Validation loss: 0.21371\n",
      "Epoch 14/1024 [0.136secs] -> Train loss: 0.21371 | Validation loss: 0.21902\n",
      "Epoch 15/1024 [0.134secs] -> Train loss: 0.21902 | Validation loss: 0.21368\n",
      "Epoch 16/1024 [0.138secs] -> Train loss: 0.21368 | Validation loss: 0.20231\n",
      "Epoch 17/1024 [0.136secs] -> Train loss: 0.20231 | Validation loss: 0.19101\n",
      "Epoch 18/1024 [0.138secs] -> Train loss: 0.19101 | Validation loss: 0.18420\n",
      "Epoch 19/1024 [0.135secs] -> Train loss: 0.18420 | Validation loss: 0.18323\n",
      "Epoch 20/1024 [0.134secs] -> Train loss: 0.18323 | Validation loss: 0.18663\n",
      "Epoch 21/1024 [0.134secs] -> Train loss: 0.18663 | Validation loss: 0.19142\n",
      "Epoch 22/1024 [0.134secs] -> Train loss: 0.19142 | Validation loss: 0.19477\n",
      "Epoch 23/1024 [0.137secs] -> Train loss: 0.19477 | Validation loss: 0.19514\n",
      "Epoch 24/1024 [0.137secs] -> Train loss: 0.19514 | Validation loss: 0.19260\n",
      "Epoch 25/1024 [0.137secs] -> Train loss: 0.19260 | Validation loss: 0.18843\n",
      "Epoch 26/1024 [0.136secs] -> Train loss: 0.18843 | Validation loss: 0.18436\n",
      "Epoch 27/1024 [0.135secs] -> Train loss: 0.18436 | Validation loss: 0.18173\n",
      "Epoch 28/1024 [0.134secs] -> Train loss: 0.18173 | Validation loss: 0.18105\n",
      "Epoch 29/1024 [0.135secs] -> Train loss: 0.18105 | Validation loss: 0.18191\n",
      "Epoch 30/1024 [0.212secs] -> Train loss: 0.18191 | Validation loss: 0.18335\n",
      "Epoch 31/1024 [0.137secs] -> Train loss: 0.18335 | Validation loss: 0.18431\n",
      "Epoch 32/1024 [0.136secs] -> Train loss: 0.18431 | Validation loss: 0.18409\n",
      "Epoch 33/1024 [0.138secs] -> Train loss: 0.18409 | Validation loss: 0.18262\n",
      "Epoch 34/1024 [0.137secs] -> Train loss: 0.18262 | Validation loss: 0.18034\n",
      "Epoch 35/1024 [0.136secs] -> Train loss: 0.18034 | Validation loss: 0.17797\n",
      "Epoch 36/1024 [0.136secs] -> Train loss: 0.17797 | Validation loss: 0.17609\n",
      "Epoch 37/1024 [0.134secs] -> Train loss: 0.17609 | Validation loss: 0.17493\n",
      "Epoch 38/1024 [0.134secs] -> Train loss: 0.17493 | Validation loss: 0.17429\n",
      "Epoch 39/1024 [0.133secs] -> Train loss: 0.17429 | Validation loss: 0.17363\n",
      "Epoch 40/1024 [0.133secs] -> Train loss: 0.17363 | Validation loss: 0.17237\n",
      "Epoch 41/1024 [0.134secs] -> Train loss: 0.17237 | Validation loss: 0.17013\n",
      "Epoch 42/1024 [0.134secs] -> Train loss: 0.17013 | Validation loss: 0.16683\n",
      "Epoch 43/1024 [0.133secs] -> Train loss: 0.16683 | Validation loss: 0.16263\n",
      "Epoch 44/1024 [0.134secs] -> Train loss: 0.16263 | Validation loss: 0.15777\n",
      "Epoch 45/1024 [0.134secs] -> Train loss: 0.15777 | Validation loss: 0.15234\n",
      "Epoch 46/1024 [0.134secs] -> Train loss: 0.15234 | Validation loss: 0.14600\n",
      "Epoch 47/1024 [0.133secs] -> Train loss: 0.14600 | Validation loss: 0.13811\n",
      "Epoch 48/1024 [0.133secs] -> Train loss: 0.13811 | Validation loss: 0.12723\n",
      "Epoch 49/1024 [0.133secs] -> Train loss: 0.12723 | Validation loss: 0.11342\n",
      "Epoch 50/1024 [0.134secs] -> Train loss: 0.11342 | Validation loss: 0.09928\n",
      "Epoch 51/1024 [0.134secs] -> Train loss: 0.09928 | Validation loss: 0.08898\n",
      "Epoch 52/1024 [0.133secs] -> Train loss: 0.08898 | Validation loss: 0.08579\n",
      "Epoch 53/1024 [0.133secs] -> Train loss: 0.08579 | Validation loss: 0.09298\n",
      "Epoch 54/1024 [0.133secs] -> Train loss: 0.09298 | Validation loss: 0.09978\n",
      "Epoch 55/1024 [0.134secs] -> Train loss: 0.09978 | Validation loss: 0.09778\n",
      "Epoch 56/1024 [0.134secs] -> Train loss: 0.09778 | Validation loss: 0.08983\n",
      "Epoch 57/1024 [0.136secs] -> Train loss: 0.08983 | Validation loss: 0.08303\n",
      "Epoch 58/1024 [0.136secs] -> Train loss: 0.08303 | Validation loss: 0.08087\n",
      "Epoch 59/1024 [0.135secs] -> Train loss: 0.08087 | Validation loss: 0.08205\n",
      "Epoch 60/1024 [0.135secs] -> Train loss: 0.08205 | Validation loss: 0.08396\n",
      "Epoch 61/1024 [0.137secs] -> Train loss: 0.08396 | Validation loss: 0.08516\n",
      "Epoch 62/1024 [0.136secs] -> Train loss: 0.08516 | Validation loss: 0.08513\n",
      "Epoch 63/1024 [0.135secs] -> Train loss: 0.08513 | Validation loss: 0.08389\n",
      "Epoch 64/1024 [0.134secs] -> Train loss: 0.08389 | Validation loss: 0.08180\n",
      "Epoch 65/1024 [0.134secs] -> Train loss: 0.08180 | Validation loss: 0.07967\n",
      "Epoch 66/1024 [0.134secs] -> Train loss: 0.07967 | Validation loss: 0.07843\n",
      "Epoch 67/1024 [0.133secs] -> Train loss: 0.07843 | Validation loss: 0.07840\n",
      "Epoch 68/1024 [0.134secs] -> Train loss: 0.07840 | Validation loss: 0.07883\n",
      "Epoch 69/1024 [0.133secs] -> Train loss: 0.07883 | Validation loss: 0.07891\n",
      "Epoch 70/1024 [0.134secs] -> Train loss: 0.07891 | Validation loss: 0.07839\n",
      "Epoch 71/1024 [0.211secs] -> Train loss: 0.07839 | Validation loss: 0.07753\n",
      "Epoch 72/1024 [0.136secs] -> Train loss: 0.07753 | Validation loss: 0.07711\n",
      "Epoch 73/1024 [0.136secs] -> Train loss: 0.07711 | Validation loss: 0.07724\n",
      "Epoch 74/1024 [0.136secs] -> Train loss: 0.07724 | Validation loss: 0.07748\n",
      "Epoch 75/1024 [0.134secs] -> Train loss: 0.07748 | Validation loss: 0.07748\n",
      "Epoch 76/1024 [0.134secs] -> Train loss: 0.07748 | Validation loss: 0.07712\n",
      "Epoch 77/1024 [0.133secs] -> Train loss: 0.07712 | Validation loss: 0.07646\n",
      "Epoch 78/1024 [0.134secs] -> Train loss: 0.07646 | Validation loss: 0.07574\n",
      "Epoch 79/1024 [0.136secs] -> Train loss: 0.07574 | Validation loss: 0.07519\n",
      "Epoch 80/1024 [0.134secs] -> Train loss: 0.07519 | Validation loss: 0.07497\n",
      "Epoch 81/1024 [0.132secs] -> Train loss: 0.07497 | Validation loss: 0.07499\n",
      "Epoch 82/1024 [0.133secs] -> Train loss: 0.07499 | Validation loss: 0.07498\n",
      "Epoch 83/1024 [0.133secs] -> Train loss: 0.07498 | Validation loss: 0.07475\n",
      "Epoch 84/1024 [0.133secs] -> Train loss: 0.07475 | Validation loss: 0.07440\n",
      "Epoch 85/1024 [0.133secs] -> Train loss: 0.07440 | Validation loss: 0.07411\n",
      "Epoch 86/1024 [0.133secs] -> Train loss: 0.07411 | Validation loss: 0.07398\n",
      "Epoch 87/1024 [0.133secs] -> Train loss: 0.07398 | Validation loss: 0.07394\n",
      "Epoch 88/1024 [0.134secs] -> Train loss: 0.07394 | Validation loss: 0.07380\n",
      "Epoch 89/1024 [0.134secs] -> Train loss: 0.07380 | Validation loss: 0.07349\n",
      "Epoch 90/1024 [0.134secs] -> Train loss: 0.07349 | Validation loss: 0.07314\n",
      "Epoch 91/1024 [0.133secs] -> Train loss: 0.07314 | Validation loss: 0.07292\n",
      "Epoch 92/1024 [0.134secs] -> Train loss: 0.07292 | Validation loss: 0.07287\n",
      "Epoch 93/1024 [0.134secs] -> Train loss: 0.07287 | Validation loss: 0.07281\n",
      "Epoch 94/1024 [0.134secs] -> Train loss: 0.07281 | Validation loss: 0.07262\n",
      "Epoch 95/1024 [0.134secs] -> Train loss: 0.07262 | Validation loss: 0.07234\n",
      "Epoch 96/1024 [0.133secs] -> Train loss: 0.07234 | Validation loss: 0.07215\n",
      "Epoch 97/1024 [0.133secs] -> Train loss: 0.07215 | Validation loss: 0.07205\n",
      "Epoch 98/1024 [0.134secs] -> Train loss: 0.07205 | Validation loss: 0.07193\n",
      "Epoch 99/1024 [0.134secs] -> Train loss: 0.07193 | Validation loss: 0.07172\n",
      "Epoch 100/1024 [0.134secs] -> Train loss: 0.07172 | Validation loss: 0.07148\n",
      "Epoch 101/1024 [0.134secs] -> Train loss: 0.07148 | Validation loss: 0.07132\n",
      "Epoch 102/1024 [0.133secs] -> Train loss: 0.07132 | Validation loss: 0.07124\n",
      "Epoch 103/1024 [0.134secs] -> Train loss: 0.07124 | Validation loss: 0.07112\n",
      "Epoch 104/1024 [0.134secs] -> Train loss: 0.07112 | Validation loss: 0.07092\n",
      "Epoch 105/1024 [0.134secs] -> Train loss: 0.07092 | Validation loss: 0.07074\n",
      "Epoch 106/1024 [0.134secs] -> Train loss: 0.07074 | Validation loss: 0.07062\n",
      "Epoch 107/1024 [0.134secs] -> Train loss: 0.07062 | Validation loss: 0.07049\n",
      "Epoch 108/1024 [0.134secs] -> Train loss: 0.07049 | Validation loss: 0.07031\n",
      "Epoch 109/1024 [0.133secs] -> Train loss: 0.07031 | Validation loss: 0.07013\n",
      "Epoch 110/1024 [0.133secs] -> Train loss: 0.07013 | Validation loss: 0.06998\n",
      "Epoch 111/1024 [0.133secs] -> Train loss: 0.06998 | Validation loss: 0.06985\n",
      "Epoch 112/1024 [0.209secs] -> Train loss: 0.06985 | Validation loss: 0.06969\n",
      "Epoch 113/1024 [0.136secs] -> Train loss: 0.06969 | Validation loss: 0.06950\n",
      "Epoch 114/1024 [0.136secs] -> Train loss: 0.06950 | Validation loss: 0.06933\n",
      "Epoch 115/1024 [0.135secs] -> Train loss: 0.06933 | Validation loss: 0.06918\n",
      "Epoch 116/1024 [0.134secs] -> Train loss: 0.06918 | Validation loss: 0.06902\n",
      "Epoch 117/1024 [0.134secs] -> Train loss: 0.06902 | Validation loss: 0.06884\n",
      "Epoch 118/1024 [0.134secs] -> Train loss: 0.06884 | Validation loss: 0.06869\n",
      "Epoch 119/1024 [0.134secs] -> Train loss: 0.06869 | Validation loss: 0.06857\n",
      "Epoch 120/1024 [0.134secs] -> Train loss: 0.06857 | Validation loss: 0.06844\n",
      "Epoch 121/1024 [0.134secs] -> Train loss: 0.06844 | Validation loss: 0.06832\n",
      "Epoch 122/1024 [0.134secs] -> Train loss: 0.06832 | Validation loss: 0.06823\n",
      "Epoch 123/1024 [0.133secs] -> Train loss: 0.06823 | Validation loss: 0.06816\n",
      "Epoch 124/1024 [0.133secs] -> Train loss: 0.06816 | Validation loss: 0.06809\n",
      "Epoch 125/1024 [0.133secs] -> Train loss: 0.06809 | Validation loss: 0.06801\n",
      "Epoch 126/1024 [0.134secs] -> Train loss: 0.06801 | Validation loss: 0.06795\n",
      "Epoch 127/1024 [0.133secs] -> Train loss: 0.06795 | Validation loss: 0.06788\n",
      "Epoch 128/1024 [0.133secs] -> Train loss: 0.06788 | Validation loss: 0.06779\n",
      "Epoch 129/1024 [0.134secs] -> Train loss: 0.06779 | Validation loss: 0.06770\n",
      "Epoch 130/1024 [0.134secs] -> Train loss: 0.06770 | Validation loss: 0.06761\n",
      "Epoch 131/1024 [0.134secs] -> Train loss: 0.06761 | Validation loss: 0.06750\n",
      "Epoch 132/1024 [0.134secs] -> Train loss: 0.06750 | Validation loss: 0.06739\n",
      "Epoch 133/1024 [0.134secs] -> Train loss: 0.06739 | Validation loss: 0.06729\n",
      "Epoch 134/1024 [0.133secs] -> Train loss: 0.06729 | Validation loss: 0.06719\n",
      "Epoch 135/1024 [0.133secs] -> Train loss: 0.06719 | Validation loss: 0.06710\n",
      "Epoch 136/1024 [0.136secs] -> Train loss: 0.06710 | Validation loss: 0.06702\n",
      "Epoch 137/1024 [0.134secs] -> Train loss: 0.06702 | Validation loss: 0.06694\n",
      "Epoch 138/1024 [0.133secs] -> Train loss: 0.06694 | Validation loss: 0.06687\n",
      "Epoch 139/1024 [0.133secs] -> Train loss: 0.06687 | Validation loss: 0.06681\n",
      "Epoch 140/1024 [0.133secs] -> Train loss: 0.06681 | Validation loss: 0.06674\n",
      "Epoch 141/1024 [0.134secs] -> Train loss: 0.06674 | Validation loss: 0.06668\n",
      "Epoch 142/1024 [0.133secs] -> Train loss: 0.06668 | Validation loss: 0.06662\n",
      "Epoch 143/1024 [0.134secs] -> Train loss: 0.06662 | Validation loss: 0.06655\n",
      "Epoch 144/1024 [0.133secs] -> Train loss: 0.06655 | Validation loss: 0.06649\n",
      "Epoch 145/1024 [0.134secs] -> Train loss: 0.06649 | Validation loss: 0.06643\n",
      "Epoch 146/1024 [0.134secs] -> Train loss: 0.06643 | Validation loss: 0.06637\n",
      "Epoch 147/1024 [0.134secs] -> Train loss: 0.06637 | Validation loss: 0.06632\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 64\u001b[0m\n\u001b[1;32m     61\u001b[0m exp\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mfit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: temp_train(exp\u001b[38;5;241m.\u001b[39mmodel, x)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m \u001b[43mexp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m1e-2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mverbose\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/Time-Series-Transformers/experiment.py:107\u001b[0m, in \u001b[0;36mExperiment.train\u001b[0;34m(self, train_conf)\u001b[0m\n\u001b[1;32m    105\u001b[0m train_conf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_dataset\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_dataset\n\u001b[1;32m    106\u001b[0m train_conf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation_dataset\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidation_dataset\n\u001b[0;32m--> 107\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_conf\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 61\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m verbose: \n\u001b[1;32m     58\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimr\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124msecs] -> Train loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Validation loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 61\u001b[0m exp\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mfit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mtemp_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     64\u001b[0m exp\u001b[38;5;241m.\u001b[39mtrain({\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m1024\u001b[39m,\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m1e-2\u001b[39m,\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m1024\u001b[39m,\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     69\u001b[0m })\n",
      "Cell \u001b[0;32mIn[7], line 52\u001b[0m, in \u001b[0;36mtemp_train\u001b[0;34m(self, conf)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# if there are a validation set\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidation_loss_history\u001b[38;5;241m.\u001b[39mappend(val_loss\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loss_history\u001b[38;5;241m.\u001b[39mappend(epoch_loss\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "Cell \u001b[0;32mIn[5], line 134\u001b[0m, in \u001b[0;36mTimeSeriesTransformer.validate\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    133\u001b[0m memory_mask, tgt_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_train_masks()\n\u001b[0;32m--> 134\u001b[0m memory_mask, tgt_mask \u001b[38;5;241m=\u001b[39m \u001b[43mmemory_mask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m, tgt_mask\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "exp = Experiment(\n",
    "    {\n",
    "        # Model\n",
    "        'model': model,\n",
    "        'input_len':input_len,\n",
    "        'feature_dim':1,\n",
    "        'forecast_horizon':fh,\n",
    "        # Data\n",
    "        'frequency':'daily',\n",
    "        'scaler':MinMaxScaler((-1,1)),\n",
    "        'decompose': False, #detrend and de-sazonalize\n",
    "        'freq':1,\n",
    "        # Others\n",
    "        'device':'cuda',\n",
    "        'verbose':True,\n",
    "    })\n",
    "#\n",
    "\n",
    "exp.set_dataset(linear_serie=train_set.Elec_kW.values, train=True)\n",
    "exp.set_dataset(linear_serie=valid_set.Elec_kW.values, validation=True)\n",
    "#\n",
    "def temp_train(self, conf):\n",
    "    expected_vars = ['epochs','lr','batch_size','train_dataset']\n",
    "    for v in expected_vars:\n",
    "        assert v in conf.keys(), f'Key \"{v}\" is missing on params dict'\n",
    "    #\n",
    "    epochs = conf['epochs']\n",
    "    verbose = conf['verbose']\n",
    "    train_dataset = conf['train_dataset']\n",
    "    val_dataset = conf.get('train_dataset',None)\n",
    "    #\n",
    "    optimizer = torch.optim.Adam(self.parameters(), lr=conf['lr'])\n",
    "    loss_fn = nn.MSELoss()\n",
    "    train_loader = DataLoader(train_dataset, batch_size=conf['batch_size'], shuffle=True)\n",
    "    memory_mask, tgt_mask = self.get_train_masks()\n",
    "    memory_mask, tgt_mask = memory_mask.to('cuda'), tgt_mask.to('cuda')\n",
    "    for epoch_i in range(epochs):\n",
    "        timr = time.time()\n",
    "        epoch_loss = .0\n",
    "        val_loss = -1\n",
    "        for enc_x, dec_x, tgt_y in train_loader:\n",
    "            optimizer.zero_grad() # current batch zero-out the loss\n",
    "            pred_y = self(enc_x, dec_x, memory_mask, tgt_mask)\n",
    "            loss = loss_fn(pred_y, tgt_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss        \n",
    "        # end epoch\n",
    "        epoch_loss = epoch_loss/len(train_loader)\n",
    "        # if there are a validation set\n",
    "        if val_dataset is not None:\n",
    "            val_loss = self.validate(val_dataset)\n",
    "            self.validation_loss_history.append(val_loss.to('cpu').detach().numpy())\n",
    "        self.train_loss_history.append(epoch_loss.to('cpu').detach().numpy())\n",
    "        #     \n",
    "        timr = time.time() - timr\n",
    "        if verbose: \n",
    "            print(f'Epoch {epoch_i+1}/{epochs} [{timr:.3f}secs] -> Train loss: {epoch_loss:.5f} | Validation loss: {val_loss:.5f}')\n",
    "\n",
    "    \n",
    "exp.model.fit = lambda x: temp_train(exp.model, x)\n",
    "\n",
    "#\n",
    "exp.train({\n",
    "    'epochs':1024,\n",
    "    'lr':1e-2,\n",
    "    'batch_size':1024,\n",
    "    'verbose':True,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TransformerWithPE' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m last_train_values \u001b[38;5;241m=\u001b[39m train_set\u001b[38;5;241m.\u001b[39mElec_kW\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m-\u001b[39minput_len:]\n\u001b[1;32m      2\u001b[0m next_validation_values \u001b[38;5;241m=\u001b[39m valid_set\u001b[38;5;241m.\u001b[39mElec_kW\u001b[38;5;241m.\u001b[39mvalues[:fh]\n\u001b[0;32m----> 3\u001b[0m pred_y \u001b[38;5;241m=\u001b[39m \u001b[43mexp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlast_train_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m exp\u001b[38;5;241m.\u001b[39mprint_metrics(next_validation_values, pred_y)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/Time-Series-Transformers/experiment.py:134\u001b[0m, in \u001b[0;36mExperiment.predict\u001b[0;34m(self, ts, forecast_horizon)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m(\u001b[38;5;28mlen\u001b[39m(ts) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_len)\n\u001b[1;32m    133\u001b[0m ts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(ts) \u001b[38;5;66;03m# TODO add ts copy \u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m(ts, forecast_horizon)\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# rescale and add trend, etc..\u001b[39;00m\n\u001b[1;32m    136\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposprocess(output)\n",
      "File \u001b[0;32m/workspace/Time-Series-Transformers/.conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1688\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1687\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1688\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TransformerWithPE' object has no attribute 'predict'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
