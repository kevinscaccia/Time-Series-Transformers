{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Class Definition\n",
    "- Helper class that defines the functions common to all model training(time series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from models.cnn import SimpleCNN\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of train_set : 0.87%\n",
      "Proportion of valid_set : 0.13%\n"
     ]
    }
   ],
   "source": [
    "solar_power = pd.read_csv('./data/solarpanelspower/PV_Elec_Gas2.csv').rename(columns={'Unnamed: 0':'date'}).set_index('date')\n",
    "\n",
    "train_set = solar_power[:'2018-10-31']\n",
    "valid_set = solar_power['2018-11-01':'2019-11-18']\n",
    "test_set = solar_power['2019-11-18':]\n",
    "print('Proportion of train_set : {:.2f}%'.format(len(train_set)/len(solar_power)))\n",
    "print('Proportion of valid_set : {:.2f}%'.format(len(valid_set)/len(solar_power)))\n",
    "# print('Proportion of test_set : {:.2f}%'.format(len(test_set)/len(solar_power)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting experiment.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile experiment.py\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "from torch import nn\n",
    "from utils.timeserie import split_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "#\n",
    "from utils.ml import SimpleDataset\n",
    "\n",
    "class Experiment():\n",
    "\n",
    "    def __init__(self, config: dict):\n",
    "        # Set experiment config\n",
    "        expected_vars = ['model','input_len','feature_dim','frequency',\n",
    "                         'device','scaler','verbose']\n",
    "        for v in expected_vars:\n",
    "            assert v in config.keys(), f'Key \"{v}\" is missing on params dict'\n",
    "            vars(self)[v] = config[v]\n",
    "        self.config = config\n",
    "        #\n",
    "        # Pre-configuration (to produce same result in inference/predict)\n",
    "        #\n",
    "        np.random.seed(7); torch.manual_seed(7)\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.manual_seed_all(7)\n",
    "        #\n",
    "        #\n",
    "        #\n",
    "        self.model = self.model.to(self.device)\n",
    "\n",
    "\n",
    "\n",
    "    def split_chunks(self, linear_serie, expand_dim=True):\n",
    "        x, y = split_sequence(linear_serie, self.input_len)\n",
    "        x, y = torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)\n",
    "        if expand_dim:\n",
    "            x, y = x.unsqueeze(-1), y.unsqueeze(-1)\n",
    "        return x, y\n",
    "\n",
    "    def set_dataset(self, linear_serie, train=False, validation=False):\n",
    "        if self.scaler is not None:\n",
    "            if train: # FIT Scaler\n",
    "                if self.verbose: print('Scaler FIT')\n",
    "                linear_serie = self.scaler.fit_transform(linear_serie.reshape(-1,1)).reshape(-1)\n",
    "            if validation:\n",
    "                linear_serie = self.scaler.transform(linear_serie.reshape(-1,1)).reshape(-1)\n",
    "\n",
    "            \n",
    "        x, y = self.split_chunks(linear_serie)\n",
    "        x, y = x.to(self.device), y.to(self.device)\n",
    "        data = SimpleDataset(x, y)\n",
    "        # Save\n",
    "        if train:\n",
    "            self.train_dataset = data\n",
    "        if validation:\n",
    "            self.validation_dataset = data\n",
    "        \n",
    "        return data\n",
    "    \n",
    "\n",
    "    def train(self, train_conf):\n",
    "        expected_vars = ['epochs','lr','batch_size']\n",
    "        for v in expected_vars:\n",
    "            assert v in train_conf.keys(), f'Key \"{v}\" is missing on params dict'\n",
    "        #\n",
    "        epochs = train_conf['epochs']\n",
    "        verbose = train_conf['verbose']\n",
    "        #\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=train_conf['lr'])\n",
    "        loss_fn = nn.MSELoss()\n",
    "        train_loader = DataLoader(self.train_dataset, batch_size=train_conf['batch_size'], shuffle=False)\n",
    "        \n",
    "        loss_history = []\n",
    "        for epoch_i in range(epochs):\n",
    "            timr = time.time()\n",
    "            epoch_loss = .0\n",
    "            for batch_x, batch_y in train_loader:\n",
    "                optimizer.zero_grad() # current batch zero-out the loss\n",
    "                pred_y = self.model(batch_x)\n",
    "                loss = loss_fn(pred_y, batch_y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                epoch_loss += loss\n",
    "            # end epoch\n",
    "            epoch_loss = epoch_loss/len(train_loader)\n",
    "            loss_history.append(epoch_loss.to('cpu').detach().numpy())\n",
    "            timr = time.time() - timr\n",
    "            if verbose: print(f'Epoch {epoch_i+1}/{epochs} [{timr:.3f}secs] -> Train loss: {epoch_loss:.5f}')\n",
    "    \n",
    "    def predict(self, linear_serie):\n",
    "        if self.scaler is not None:\n",
    "            linear_serie = self.scaler.transform(linear_serie.reshape(-1,1)).reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Experiment Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = Experiment(\n",
    "    {\n",
    "        # Model\n",
    "        'model': SimpleCNN(3, 64),\n",
    "        'input_len':3,\n",
    "        'feature_dim':1,\n",
    "        # Data\n",
    "        'frequency':'daily',\n",
    "        'scaler':MinMaxScaler(),\n",
    "        # Others\n",
    "        'device':'cuda',\n",
    "        'verbose':True,\n",
    "    })\n",
    "\n",
    "exp.set_dataset(linear_serie=train_set.Elec_kW.values, train=True)\n",
    "exp.set_dataset(linear_serie=valid_set.Elec_kW.values, validation=True)\n",
    "\n",
    "exp.train({\n",
    "    'epochs':2,\n",
    "    'lr':1e-5,\n",
    "    'batch_size':2,\n",
    "    'verbose':True,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.preprocessing._data.MinMaxScaler"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "valid_losses = []\n",
    "def Train():\n",
    "    \n",
    "    running_loss = .0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for idx, (inputs,labels) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(inputs)\n",
    "        loss = criterion(preds,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss\n",
    "        \n",
    "    train_loss = running_loss/len(train_loader)\n",
    "    train_losses.append(train_loss.to('cpu').detach().numpy())\n",
    "    \n",
    "    print(f'train_loss {train_loss}')\n",
    "    \n",
    "def Valid():\n",
    "    running_loss = .0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, (inputs, labels) in enumerate(valid_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(inputs.float())\n",
    "            loss = criterion(preds,labels)\n",
    "            running_loss += loss\n",
    "            \n",
    "        valid_loss = running_loss/len(valid_loader)\n",
    "        valid_losses.append(valid_loss.to('cpu').detach().numpy())\n",
    "        print(f'valid_loss {valid_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "for epoch in range(epochs):\n",
    "    print('epochs {}/{}'.format(epoch+1,epochs))\n",
    "    Train()\n",
    "    Valid()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_losses,label='train_loss')\n",
    "plt.plot(valid_losses,label='valid_loss')\n",
    "plt.title('MSE Loss')\n",
    "plt.ylim(0, 100)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_x , target_y = split_sequence(train_set.Elec_kW.values,n_steps)\n",
    "inputs = target_x.reshape(target_x.shape[0],target_x.shape[1],1)\n",
    "inputs = torch.tensor(inputs, dtype=torch.float32).to('cpu')\n",
    "\n",
    "model.eval()\n",
    "model = model.to('cpu')\n",
    "prediction = []\n",
    "batch_size = 2\n",
    "iterations =  int(inputs.shape[0]/2)\n",
    "\n",
    "for i in range(iterations):\n",
    "    preds = model(torch.tensor(inputs[batch_size*i:batch_size*(i+1)]))\n",
    "    prediction.append(preds.detach().numpy())\n",
    "fig, ax = plt.subplots(1, 2,figsize=(11,4))\n",
    "ax[0].set_title('predicted one')\n",
    "ax[0].plot(prediction)\n",
    "ax[1].set_title('real one')\n",
    "ax[1].plot(target_y)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
