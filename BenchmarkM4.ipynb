{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M4 Dataset Benchmark Code\n",
    "> Generic code to experiment and produce the final benchmark.py codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python\n",
    "import argparse\n",
    "import numpy as np\n",
    "# ml\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import mlflow\n",
    "# local\n",
    "from models.benchmark import NaivePredictor\n",
    "from models.cnn import SimpleCNN\n",
    "from models.transformer import VanillaTransformer, DecoderOnlyTransformer\n",
    "from utils.plot import plot_predictions\n",
    "from experiment import Experiment\n",
    "from utils.m4 import smape, mase, M4DatasetGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRACK = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.ml import EarlyStopperPercent\n",
    "import torch\n",
    "from utils.m4 import get_x_y\n",
    "from utils.ml import DecoderDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading M4 Data...\n",
      "Loaded:\n",
      "    => Weekly has 359 series\n",
      "W176\n"
     ]
    }
   ],
   "source": [
    "model_name = ['vanilla_transformer','cnn','decoder_transformer'][2]\n",
    "run_sp = 'Weekly'\n",
    "\n",
    "assert(model_name in ['cnn','naive', 'vanilla_transformer','decoder_transformer'])\n",
    "assert run_sp in ['Hourly','Daily','Weekly','Monthly','Quarterly','Yearly']\n",
    "m4_data = M4DatasetGenerator([run_sp])\n",
    "\n",
    "def get_model(model_name, model_conf):\n",
    "    if model_name == 'cnn':\n",
    "        return SimpleCNN(model_conf['block_size'], model_conf['d_model'])\n",
    "    elif model_name == 'naive':\n",
    "        return NaivePredictor()\n",
    "    elif model_name == 'vanilla_transformer':\n",
    "        return  VanillaTransformer(model_conf)\n",
    "    elif model_name == 'decoder_transformer':\n",
    "        m = DecoderOnlyTransformer(model_conf)\n",
    "        return torch.load('trained/decoder_only_weekly_38.model').to('cuda')\n",
    "    \n",
    "if TRACK:\n",
    "    mlflow.set_tracking_uri(uri=\"http://127.0.0.1:5000\")\n",
    "    mlflow.set_experiment(f\"M4Benchmark {model_name}\")\n",
    "    mlflow.set_experiment_tag('model', model_name)\n",
    "\n",
    "np.random.seed(123)\n",
    "#\n",
    "# Inicializations\n",
    "#\n",
    "metrics_table = {'serie_id':[],'smape':[],'mase':[],}\n",
    "smape_list, mase_list = [], []\n",
    "num_of_series = m4_data.data_dict[run_sp]['num']\n",
    "block_size = m4_data.data_dict[run_sp]['fh']\n",
    "fh = m4_data.data_dict[run_sp]['fh']\n",
    "#\n",
    "# Model Hiperparams\n",
    "#\n",
    "d_model = 64\n",
    "batch_size = 512 #512\n",
    "epochs = 128\n",
    "scaler = MinMaxScaler((-1,1))\n",
    "decompose = False\n",
    "MAX_SERIES = 10\n",
    "#\n",
    "# model_conf = {'block_size':block_size, 'd_model':d_model}\n",
    "if model_name == 'vanilla_transformer':\n",
    "    model_conf = {'block_size':block_size, 'd_model': 16, 'num_heads': 2, 'num_layers': 2,'dim_feedforward':128,'device':'cuda'}\n",
    "    lr = 1e-4\n",
    "elif model_name == 'decoder_transformer':\n",
    "    model_conf = {\n",
    "    'd_model': 32, \n",
    "    'num_heads': 4, \n",
    "    'num_layers': 4,\n",
    "    'dim_feedforward':128,\n",
    "    'block_size':512,\n",
    "    'device':'cuda',\n",
    "    'pad_token':-20\n",
    "}\n",
    "    lr = 1e-4\n",
    "else:\n",
    "    lr = 1e-3\n",
    "\n",
    "#\n",
    "if TRACK:\n",
    "    mlflow.start_run(run_name=f'{run_sp}')\n",
    "    mlflow.log_param('model_name', model_name)\n",
    "    mlflow.log_param('d_model', d_model)\n",
    "    mlflow.log_param('block_size', block_size)\n",
    "    mlflow.log_param('forecast_horizon', fh)\n",
    "    mlflow.log_param('decompose', decompose)\n",
    "\n",
    "    mlflow.log_param('series', num_of_series)\n",
    "    mlflow.log_param('scaler', scaler)\n",
    "    mlflow.log_param('batch_size', batch_size)\n",
    "    mlflow.log_param('epochs', epochs)\n",
    "    mlflow.log_param('lr', lr)\n",
    "    \n",
    "for train_serie, test_serie, serie_id, fh, freq, serie_sp in m4_data.generate(n_series=MAX_SERIES, random=True):\n",
    "    assert fh == block_size\n",
    "    model = get_model(model_name, model_conf) #\n",
    "    \n",
    "    exp_conf = {\n",
    "            # Model\n",
    "            'model': model,\n",
    "            'model_n_parameters': sum(p.numel() for p in model.parameters() if p.requires_grad), \n",
    "            'input_len':block_size,\n",
    "            'forecast_horizon':fh,\n",
    "            'feature_dim':1,\n",
    "            # Data\n",
    "            'frequency':serie_sp.lower(),\n",
    "            'scaler':scaler,\n",
    "            'decompose': decompose, #detrend and de-sazonalize\n",
    "            'freq':freq,\n",
    "            # Others\n",
    "            'device':'cuda',\n",
    "            'verbose':False,\n",
    "    }\n",
    "    train_conf = {\n",
    "        'epochs':epochs,\n",
    "        'lr':lr, \n",
    "        'batch_size':batch_size,\n",
    "        'validate_freq':10,\n",
    "        'verbose':False, # stop training if loss dont decrease 0.5% 5 consecutive steps\n",
    "        'early_stop':EarlyStopperPercent(patience=5, min_percent=0.005, verbose=False),\n",
    "    }\n",
    "    if model_name == 'decoder_transformer':\n",
    "        print(serie_id)\n",
    "        train_x = torch.tensor(scaler.fit_transform(train_serie.reshape(-1, 1)).reshape(-1), dtype=torch.float32)\n",
    "\n",
    "        x, y, m = get_x_y(train_x, block_size=512)\n",
    "        train_conf['train_dataset'] = DecoderDataset(x.unsqueeze(-1), y.unsqueeze(-1), m)\n",
    "        model.fit(train_conf)\n",
    "\n",
    "        train_x = train_x.to('cuda').view(1, -1, 1)\n",
    "        pred_y = model.predict(train_x, len(test_serie)).cpu().numpy()\n",
    "        pred_y = scaler.inverse_transform(pred_y.reshape(-1,1)).reshape(-1)\n",
    "\n",
    "\n",
    "\n",
    "    else:\n",
    "        exp = Experiment(exp_conf)\n",
    "        exp.set_dataset(linear_serie=train_serie, train=True)\n",
    "        # exp.set_dataset(linear_serie=test_serie)\n",
    "        exp.train(train_conf)\n",
    "        # test\n",
    "        last_train_values = train_serie[-block_size:]\n",
    "        pred_y = exp.predict(last_train_values, fh)\n",
    "    \n",
    "    # check if negative or extreme (M4)\n",
    "    pred_y[pred_y < 0] = 0\n",
    "    pred_y[pred_y > (1000 * np.max(train_serie))] = np.max(train_serie)\n",
    "\n",
    "    # Metrics\n",
    "    metrics_table['serie_id'].append(serie_id)\n",
    "    metrics_table['smape'].append(smape(test_serie, pred_y)*100)\n",
    "    metrics_table['mase'].append(mase(train_serie, test_serie, pred_y, freq))\n",
    "    print(f'Serie {serie_id}-{serie_sp} Finished')\n",
    "    plot_predictions(train_serie, test_serie, pred_y)\n",
    "    \n",
    "#\n",
    "metrics_dict = {\n",
    "    'smape_mean': np.round(np.mean(metrics_table['smape'], dtype=float), 3), \n",
    "    'mase_mean':  np.round(np.mean(metrics_table['mase'], dtype=float), 3),\n",
    "    #\n",
    "    'smape_std':  np.round(np.std(metrics_table['smape'], dtype=float), 3),\n",
    "    'mase_std':   np.round(np.std(metrics_table['mase'], dtype=float), 3),\n",
    "}\n",
    "if TRACK:\n",
    "    mlflow.log_metrics(metrics_dict)\n",
    "    mlflow.log_table(metrics_table, artifact_file='metrics_table')\n",
    "\n",
    "print(f'''\n",
    "    Experiment Finished\n",
    "''')\n",
    "for k, v in metrics_dict.items(): print(f'      {k}: {v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
